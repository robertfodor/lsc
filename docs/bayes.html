<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 Introduction to Bayesian statistics | Learning Statistics with CogStat</title>
  <meta name="description" content="Chapter 9 Introduction to Bayesian statistics | Learning Statistics with CogStat covers the contents of an introductory statistics class, as typically taught to undergraduate psychology students based on Danielle Navarro’s original Learning Statistics with R with a focus on automatic statistical analysis performed in CogStat." />
  <meta name="generator" content="bookdown 0.28 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 Introduction to Bayesian statistics | Learning Statistics with CogStat" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Chapter 9 Introduction to Bayesian statistics | Learning Statistics with CogStat covers the contents of an introductory statistics class, as typically taught to undergraduate psychology students based on Danielle Navarro’s original Learning Statistics with R with a focus on automatic statistical analysis performed in CogStat." />
  <meta name="github-repo" content="https://github.com/robertfodor/lsc" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Introduction to Bayesian statistics | Learning Statistics with CogStat" />
  
  <meta name="twitter:description" content="Chapter 9 Introduction to Bayesian statistics | Learning Statistics with CogStat covers the contents of an introductory statistics class, as typically taught to undergraduate psychology students based on Danielle Navarro’s original Learning Statistics with R with a focus on automatic statistical analysis performed in CogStat." />
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="hypothesistesting.html"/>
<link rel="next" href="bayesianhypothesistests.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Learning Statistics with CogStat</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About this book</a></li>
<li class="part"><span><b>INTRODUCTIONS</b></span></li>
<li class="chapter" data-level="1" data-path="whywhywhy.html"><a href="whywhywhy.html"><i class="fa fa-check"></i><b>1</b> Why do we learn statistics?</a></li>
<li class="chapter" data-level="2" data-path="cogstat_intro.html"><a href="cogstat_intro.html"><i class="fa fa-check"></i><b>2</b> An Introduction to CogStat</a>
<ul>
<li class="chapter" data-level="2.1" data-path="cogstat_intro.html"><a href="cogstat_intro.html#foreword_cogstat"><i class="fa fa-check"></i><b>2.1</b> How CogStat came about</a></li>
<li class="chapter" data-level="2.2" data-path="cogstat_intro.html"><a href="cogstat_intro.html#autostat"><i class="fa fa-check"></i><b>2.2</b> An introduction to automatic statistical analysis</a></li>
<li class="chapter" data-level="2.3" data-path="cogstat_intro.html"><a href="cogstat_intro.html#gettingstarted"><i class="fa fa-check"></i><b>2.3</b> Getting started with CogStat</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="cogstat_intro.html"><a href="cogstat_intro.html#installing-cogstat"><i class="fa fa-check"></i><b>2.3.1</b> Installing CogStat</a></li>
<li class="chapter" data-level="2.3.2" data-path="cogstat_intro.html"><a href="cogstat_intro.html#loading-data"><i class="fa fa-check"></i><b>2.3.2</b> Loading data</a></li>
<li class="chapter" data-level="2.3.3" data-path="cogstat_intro.html"><a href="cogstat_intro.html#saving-and-exporting-your-results"><i class="fa fa-check"></i><b>2.3.3</b> Saving and exporting your results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="researchdesign.html"><a href="researchdesign.html"><i class="fa fa-check"></i><b>3</b> A brief introduction to research design</a>
<ul>
<li class="chapter" data-level="3.1" data-path="researchdesign.html"><a href="researchdesign.html#measurement"><i class="fa fa-check"></i><b>3.1</b> Introduction to psychological measurement</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="researchdesign.html"><a href="researchdesign.html#some-thoughts-about-psychological-measurement"><i class="fa fa-check"></i><b>3.1.1</b> Some thoughts about psychological measurement</a></li>
<li class="chapter" data-level="3.1.2" data-path="researchdesign.html"><a href="researchdesign.html#operationalisation-defining-your-measurement"><i class="fa fa-check"></i><b>3.1.2</b> Operationalisation: defining your measurement</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="researchdesign.html"><a href="researchdesign.html#scales"><i class="fa fa-check"></i><b>3.2</b> Scales of measurement</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="researchdesign.html"><a href="researchdesign.html#nominalscale"><i class="fa fa-check"></i><b>3.2.1</b> Nominal scale</a></li>
<li class="chapter" data-level="3.2.2" data-path="researchdesign.html"><a href="researchdesign.html#ordinalscale"><i class="fa fa-check"></i><b>3.2.2</b> Ordinal scale</a></li>
<li class="chapter" data-level="3.2.3" data-path="researchdesign.html"><a href="researchdesign.html#intervalscale"><i class="fa fa-check"></i><b>3.2.3</b> Interval scale</a></li>
<li class="chapter" data-level="3.2.4" data-path="researchdesign.html"><a href="researchdesign.html#ratioscale"><i class="fa fa-check"></i><b>3.2.4</b> Ratio scale</a></li>
<li class="chapter" data-level="3.2.5" data-path="researchdesign.html"><a href="researchdesign.html#continuousdiscrete"><i class="fa fa-check"></i><b>3.2.5</b> Continuous versus discrete variables</a></li>
<li class="chapter" data-level="3.2.6" data-path="researchdesign.html"><a href="researchdesign.html#likertscale"><i class="fa fa-check"></i><b>3.2.6</b> Some complexities: the Likert scale</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="researchdesign.html"><a href="researchdesign.html#reliability"><i class="fa fa-check"></i><b>3.3</b> Assessing the reliability of a measurement</a></li>
<li class="chapter" data-level="3.4" data-path="researchdesign.html"><a href="researchdesign.html#ivdv"><i class="fa fa-check"></i><b>3.4</b> The “role” of variables: predictors and outcomes</a></li>
<li class="chapter" data-level="3.5" data-path="researchdesign.html"><a href="researchdesign.html#researchdesigns"><i class="fa fa-check"></i><b>3.5</b> Experimental and non-experimental research</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="researchdesign.html"><a href="researchdesign.html#experimental-research"><i class="fa fa-check"></i><b>3.5.1</b> Experimental research</a></li>
<li class="chapter" data-level="3.5.2" data-path="researchdesign.html"><a href="researchdesign.html#non-experimental-research"><i class="fa fa-check"></i><b>3.5.2</b> Non-experimental research</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="researchdesign.html"><a href="researchdesign.html#validity"><i class="fa fa-check"></i><b>3.6</b> Assessing the validity of a study</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="researchdesign.html"><a href="researchdesign.html#internal-validity"><i class="fa fa-check"></i><b>3.6.1</b> Internal validity</a></li>
<li class="chapter" data-level="3.6.2" data-path="researchdesign.html"><a href="researchdesign.html#external-validity"><i class="fa fa-check"></i><b>3.6.2</b> External validity</a></li>
<li class="chapter" data-level="3.6.3" data-path="researchdesign.html"><a href="researchdesign.html#construct-validity"><i class="fa fa-check"></i><b>3.6.3</b> Construct validity</a></li>
<li class="chapter" data-level="3.6.4" data-path="researchdesign.html"><a href="researchdesign.html#face-validity"><i class="fa fa-check"></i><b>3.6.4</b> Face validity</a></li>
<li class="chapter" data-level="3.6.5" data-path="researchdesign.html"><a href="researchdesign.html#ecological-validity"><i class="fa fa-check"></i><b>3.6.5</b> Ecological validity</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="researchdesign.html"><a href="researchdesign.html#confounds-artefacts-and-other-threats-to-validity"><i class="fa fa-check"></i><b>3.7</b> Confounds, artefacts and other threats to validity</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="researchdesign.html"><a href="researchdesign.html#history-effects"><i class="fa fa-check"></i><b>3.7.1</b> History effects</a></li>
<li class="chapter" data-level="3.7.2" data-path="researchdesign.html"><a href="researchdesign.html#maturation-effects"><i class="fa fa-check"></i><b>3.7.2</b> Maturation effects</a></li>
<li class="chapter" data-level="3.7.3" data-path="researchdesign.html"><a href="researchdesign.html#repeated-testing-effects"><i class="fa fa-check"></i><b>3.7.3</b> Repeated testing effects</a></li>
<li class="chapter" data-level="3.7.4" data-path="researchdesign.html"><a href="researchdesign.html#selection-bias"><i class="fa fa-check"></i><b>3.7.4</b> Selection bias</a></li>
<li class="chapter" data-level="3.7.5" data-path="researchdesign.html"><a href="researchdesign.html#differentialattrition"><i class="fa fa-check"></i><b>3.7.5</b> Differential attrition</a></li>
<li class="chapter" data-level="3.7.6" data-path="researchdesign.html"><a href="researchdesign.html#non-response-bias"><i class="fa fa-check"></i><b>3.7.6</b> Non-response bias</a></li>
<li class="chapter" data-level="3.7.7" data-path="researchdesign.html"><a href="researchdesign.html#regression-to-the-mean"><i class="fa fa-check"></i><b>3.7.7</b> Regression to the mean</a></li>
<li class="chapter" data-level="3.7.8" data-path="researchdesign.html"><a href="researchdesign.html#experimenter-bias"><i class="fa fa-check"></i><b>3.7.8</b> Experimenter bias</a></li>
<li class="chapter" data-level="3.7.9" data-path="researchdesign.html"><a href="researchdesign.html#demand-effects-and-reactivity"><i class="fa fa-check"></i><b>3.7.9</b> Demand effects and reactivity</a></li>
<li class="chapter" data-level="3.7.10" data-path="researchdesign.html"><a href="researchdesign.html#placebo-effects"><i class="fa fa-check"></i><b>3.7.10</b> Placebo effects</a></li>
<li class="chapter" data-level="3.7.11" data-path="researchdesign.html"><a href="researchdesign.html#situation-measurement-and-subpopulation-effects"><i class="fa fa-check"></i><b>3.7.11</b> Situation, measurement and subpopulation effects</a></li>
<li class="chapter" data-level="3.7.12" data-path="researchdesign.html"><a href="researchdesign.html#fraud-deception-and-self-deception"><i class="fa fa-check"></i><b>3.7.12</b> Fraud, deception and self-deception</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="researchdesign.html"><a href="researchdesign.html#summary"><i class="fa fa-check"></i><b>3.8</b> Summary</a></li>
</ul></li>
<li class="part"><span><b>DESCRIPTIVE STATISTICS</b></span></li>
<li class="chapter" data-level="4" data-path="exploringavariable.html"><a href="exploringavariable.html"><i class="fa fa-check"></i><b>4</b> Exploring a single variable</a>
<ul>
<li class="chapter" data-level="4.1" data-path="exploringavariable.html"><a href="exploringavariable.html#centraltendency"><i class="fa fa-check"></i><b>4.1</b> Measures of central tendency</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="exploringavariable.html"><a href="exploringavariable.html#mean"><i class="fa fa-check"></i><b>4.1.1</b> The mean</a></li>
<li class="chapter" data-level="4.1.2" data-path="exploringavariable.html"><a href="exploringavariable.html#median"><i class="fa fa-check"></i><b>4.1.2</b> The median</a></li>
<li class="chapter" data-level="4.1.3" data-path="exploringavariable.html"><a href="exploringavariable.html#mean-or-median-whats-the-difference"><i class="fa fa-check"></i><b>4.1.3</b> Mean or median? What’s the difference?</a></li>
<li class="chapter" data-level="4.1.4" data-path="exploringavariable.html"><a href="exploringavariable.html#trimmedmean"><i class="fa fa-check"></i><b>4.1.4</b> Trimmed mean</a></li>
<li class="chapter" data-level="4.1.5" data-path="exploringavariable.html"><a href="exploringavariable.html#mode"><i class="fa fa-check"></i><b>4.1.5</b> Mode</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="exploringavariable.html"><a href="exploringavariable.html#var"><i class="fa fa-check"></i><b>4.2</b> Measures of variability</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="exploringavariable.html"><a href="exploringavariable.html#range"><i class="fa fa-check"></i><b>4.2.1</b> Range</a></li>
<li class="chapter" data-level="4.2.2" data-path="exploringavariable.html"><a href="exploringavariable.html#IQR"><i class="fa fa-check"></i><b>4.2.2</b> Interquartile range</a></li>
<li class="chapter" data-level="4.2.3" data-path="exploringavariable.html"><a href="exploringavariable.html#aad"><i class="fa fa-check"></i><b>4.2.3</b> Mean absolute deviation</a></li>
<li class="chapter" data-level="4.2.4" data-path="exploringavariable.html"><a href="exploringavariable.html#variance"><i class="fa fa-check"></i><b>4.2.4</b> Variance</a></li>
<li class="chapter" data-level="4.2.5" data-path="exploringavariable.html"><a href="exploringavariable.html#sd"><i class="fa fa-check"></i><b>4.2.5</b> Standard deviation</a></li>
<li class="chapter" data-level="4.2.6" data-path="exploringavariable.html"><a href="exploringavariable.html#mad"><i class="fa fa-check"></i><b>4.2.6</b> Median absolute deviation</a></li>
<li class="chapter" data-level="4.2.7" data-path="exploringavariable.html"><a href="exploringavariable.html#which-measure-to-use"><i class="fa fa-check"></i><b>4.2.7</b> Which measure to use?</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="exploringavariable.html"><a href="exploringavariable.html#skewnesskurtosis"><i class="fa fa-check"></i><b>4.3</b> Skewness and kurtosis</a></li>
<li class="chapter" data-level="4.4" data-path="exploringavariable.html"><a href="exploringavariable.html#summary-descriptives"><i class="fa fa-check"></i><b>4.4</b> Summary: descriptives</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="correl.html"><a href="correl.html"><i class="fa fa-check"></i><b>5</b> Exploring a variable pair</a>
<ul>
<li class="chapter" data-level="5.1" data-path="correl.html"><a href="correl.html#the-strength-and-direction-of-a-relationship"><i class="fa fa-check"></i><b>5.1</b> The strength and direction of a relationship</a></li>
<li class="chapter" data-level="5.2" data-path="correl.html"><a href="correl.html#pearson"><i class="fa fa-check"></i><b>5.2</b> The correlation coefficient</a></li>
<li class="chapter" data-level="5.3" data-path="correl.html"><a href="correl.html#interpretingcorrelations"><i class="fa fa-check"></i><b>5.3</b> Interpreting a correlation</a></li>
<li class="chapter" data-level="5.4" data-path="correl.html"><a href="correl.html#spearman"><i class="fa fa-check"></i><b>5.4</b> Spearman’s rank correlations</a></li>
<li class="chapter" data-level="5.5" data-path="correl.html"><a href="correl.html#missingvaluespair"><i class="fa fa-check"></i><b>5.5</b> Missing values in pairwise calculations</a></li>
<li class="chapter" data-level="5.6" data-path="correl.html"><a href="correl.html#summary-1"><i class="fa fa-check"></i><b>5.6</b> Summary</a></li>
</ul></li>
<li class="part"><span><b>INFERENTIAL STATISTICS</b></span></li>
<li class="chapter" data-level="6" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>6</b> Probability and distributions</a>
<ul>
<li class="chapter" data-level="6.1" data-path="probability.html"><a href="probability.html#probabilitystats"><i class="fa fa-check"></i><b>6.1</b> How are probability and statistics different?</a></li>
<li class="chapter" data-level="6.2" data-path="probability.html"><a href="probability.html#probabilitymeaning"><i class="fa fa-check"></i><b>6.2</b> What does probability mean?</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="probability.html"><a href="probability.html#the-frequentist-view"><i class="fa fa-check"></i><b>6.2.1</b> The frequentist view</a></li>
<li class="chapter" data-level="6.2.2" data-path="probability.html"><a href="probability.html#the-bayesian-view"><i class="fa fa-check"></i><b>6.2.2</b> The Bayesian view</a></li>
<li class="chapter" data-level="6.2.3" data-path="probability.html"><a href="probability.html#whats-the-difference-and-who-is-right"><i class="fa fa-check"></i><b>6.2.3</b> What’s the difference? And who is right?</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="probability.html"><a href="probability.html#basicprobability"><i class="fa fa-check"></i><b>6.3</b> Basic probability theory</a></li>
<li class="chapter" data-level="6.4" data-path="probability.html"><a href="probability.html#distributions"><i class="fa fa-check"></i><b>6.4</b> Distributions</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="probability.html"><a href="probability.html#binomial"><i class="fa fa-check"></i><b>6.4.1</b> The binomial distribution</a></li>
<li class="chapter" data-level="6.4.2" data-path="probability.html"><a href="probability.html#normal"><i class="fa fa-check"></i><b>6.4.2</b> The normal distribution</a></li>
<li class="chapter" data-level="6.4.3" data-path="probability.html"><a href="probability.html#density"><i class="fa fa-check"></i><b>6.4.3</b> Probability density</a></li>
<li class="chapter" data-level="6.4.4" data-path="probability.html"><a href="probability.html#otherdists"><i class="fa fa-check"></i><b>6.4.4</b> Other useful distributions</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="probability.html"><a href="probability.html#summary-2"><i class="fa fa-check"></i><b>6.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="estimation.html"><a href="estimation.html"><i class="fa fa-check"></i><b>7</b> Population, sampling, estimation</a>
<ul>
<li class="chapter" data-level="7.1" data-path="estimation.html"><a href="estimation.html#srs"><i class="fa fa-check"></i><b>7.1</b> Samples, populations and sampling</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="estimation.html"><a href="estimation.html#pop"><i class="fa fa-check"></i><b>7.1.1</b> Defining a population</a></li>
<li class="chapter" data-level="7.1.2" data-path="estimation.html"><a href="estimation.html#simple-random-samples"><i class="fa fa-check"></i><b>7.1.2</b> Simple random samples</a></li>
<li class="chapter" data-level="7.1.3" data-path="estimation.html"><a href="estimation.html#most-samples-are-not-simple-random-samples"><i class="fa fa-check"></i><b>7.1.3</b> Most samples are not simple random samples</a></li>
<li class="chapter" data-level="7.1.4" data-path="estimation.html"><a href="estimation.html#how-much-does-it-matter-if-you-dont-have-a-simple-random-sample"><i class="fa fa-check"></i><b>7.1.4</b> How much does it matter if you don’t have a simple random sample?</a></li>
<li class="chapter" data-level="7.1.5" data-path="estimation.html"><a href="estimation.html#population-parameters-and-sample-statistics"><i class="fa fa-check"></i><b>7.1.5</b> Population parameters and sample statistics</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="estimation.html"><a href="estimation.html#lawlargenumbers"><i class="fa fa-check"></i><b>7.2</b> The law of large numbers</a></li>
<li class="chapter" data-level="7.3" data-path="estimation.html"><a href="estimation.html#samplesandclt"><i class="fa fa-check"></i><b>7.3</b> Sampling distributions and the central limit theorem</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="estimation.html"><a href="estimation.html#samplingdists"><i class="fa fa-check"></i><b>7.3.1</b> Sampling distribution of the mean</a></li>
<li class="chapter" data-level="7.3.2" data-path="estimation.html"><a href="estimation.html#sampling-distributions-exist-for-any-sample-statistic"><i class="fa fa-check"></i><b>7.3.2</b> Sampling distributions exist for any sample statistic!</a></li>
<li class="chapter" data-level="7.3.3" data-path="estimation.html"><a href="estimation.html#clt"><i class="fa fa-check"></i><b>7.3.3</b> The central limit theorem</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="estimation.html"><a href="estimation.html#pointestimates"><i class="fa fa-check"></i><b>7.4</b> Estimating population parameters</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="estimation.html"><a href="estimation.html#estimating-the-population-mean"><i class="fa fa-check"></i><b>7.4.1</b> Estimating the population mean</a></li>
<li class="chapter" data-level="7.4.2" data-path="estimation.html"><a href="estimation.html#estimating-the-population-standard-deviation"><i class="fa fa-check"></i><b>7.4.2</b> Estimating the population standard deviation</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="estimation.html"><a href="estimation.html#ci"><i class="fa fa-check"></i><b>7.5</b> Estimating a confidence interval</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="estimation.html"><a href="estimation.html#a-slight-mistake-in-the-formula"><i class="fa fa-check"></i><b>7.5.1</b> A slight mistake in the formula</a></li>
<li class="chapter" data-level="7.5.2" data-path="estimation.html"><a href="estimation.html#interpreting-a-confidence-interval"><i class="fa fa-check"></i><b>7.5.2</b> Interpreting a confidence interval</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="estimation.html"><a href="estimation.html#population-parameter-estimations-in-cogstat"><i class="fa fa-check"></i><b>7.6</b> Population parameter estimations in CogStat</a></li>
<li class="chapter" data-level="7.7" data-path="estimation.html"><a href="estimation.html#summary-3"><i class="fa fa-check"></i><b>7.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="hypothesistesting.html"><a href="hypothesistesting.html"><i class="fa fa-check"></i><b>8</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="8.1" data-path="hypothesistesting.html"><a href="hypothesistesting.html#hypotheses"><i class="fa fa-check"></i><b>8.1</b> A menagerie of hypotheses</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="hypothesistesting.html"><a href="hypothesistesting.html#research-hypotheses-versus-statistical-hypotheses"><i class="fa fa-check"></i><b>8.1.1</b> Research hypotheses versus statistical hypotheses</a></li>
<li class="chapter" data-level="8.1.2" data-path="hypothesistesting.html"><a href="hypothesistesting.html#null-hypotheses-and-alternative-hypotheses"><i class="fa fa-check"></i><b>8.1.2</b> Null hypotheses and alternative hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="hypothesistesting.html"><a href="hypothesistesting.html#errortypes"><i class="fa fa-check"></i><b>8.2</b> Two types of errors</a></li>
<li class="chapter" data-level="8.3" data-path="hypothesistesting.html"><a href="hypothesistesting.html#teststatistics"><i class="fa fa-check"></i><b>8.3</b> Test statistics and sampling distributions</a></li>
<li class="chapter" data-level="8.4" data-path="hypothesistesting.html"><a href="hypothesistesting.html#decisionmaking"><i class="fa fa-check"></i><b>8.4</b> Making decisions</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="hypothesistesting.html"><a href="hypothesistesting.html#critical-regions-and-critical-values"><i class="fa fa-check"></i><b>8.4.1</b> Critical regions and critical values</a></li>
<li class="chapter" data-level="8.4.2" data-path="hypothesistesting.html"><a href="hypothesistesting.html#a-note-on-statistical-significance"><i class="fa fa-check"></i><b>8.4.2</b> A note on statistical “significance”</a></li>
<li class="chapter" data-level="8.4.3" data-path="hypothesistesting.html"><a href="hypothesistesting.html#onesidedtests"><i class="fa fa-check"></i><b>8.4.3</b> The difference between one sided and two sided tests</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="hypothesistesting.html"><a href="hypothesistesting.html#pvalue"><i class="fa fa-check"></i><b>8.5</b> The <span class="math inline">\(p\)</span> value of a test</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="hypothesistesting.html"><a href="hypothesistesting.html#a-softer-view-of-decision-making"><i class="fa fa-check"></i><b>8.5.1</b> A softer view of decision making</a></li>
<li class="chapter" data-level="8.5.2" data-path="hypothesistesting.html"><a href="hypothesistesting.html#the-probability-of-extreme-data"><i class="fa fa-check"></i><b>8.5.2</b> The probability of extreme data</a></li>
<li class="chapter" data-level="8.5.3" data-path="hypothesistesting.html"><a href="hypothesistesting.html#a-common-mistake"><i class="fa fa-check"></i><b>8.5.3</b> A common mistake</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="hypothesistesting.html"><a href="hypothesistesting.html#writeup"><i class="fa fa-check"></i><b>8.6</b> Reporting the results of a hypothesis test</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="hypothesistesting.html"><a href="hypothesistesting.html#the-issue"><i class="fa fa-check"></i><b>8.6.1</b> The issue</a></li>
<li class="chapter" data-level="8.6.2" data-path="hypothesistesting.html"><a href="hypothesistesting.html#two-proposed-solutions"><i class="fa fa-check"></i><b>8.6.2</b> Two proposed solutions</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="hypothesistesting.html"><a href="hypothesistesting.html#running-the-hypothesis-test-in-practice"><i class="fa fa-check"></i><b>8.7</b> Running the hypothesis test in practice</a></li>
<li class="chapter" data-level="8.8" data-path="hypothesistesting.html"><a href="hypothesistesting.html#effectsize"><i class="fa fa-check"></i><b>8.8</b> Effect size, sample size and power</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="hypothesistesting.html"><a href="hypothesistesting.html#the-power-function"><i class="fa fa-check"></i><b>8.8.1</b> The power function</a></li>
<li class="chapter" data-level="8.8.2" data-path="hypothesistesting.html"><a href="hypothesistesting.html#effect-size"><i class="fa fa-check"></i><b>8.8.2</b> Effect size</a></li>
<li class="chapter" data-level="8.8.3" data-path="hypothesistesting.html"><a href="hypothesistesting.html#increasing-the-power-of-your-study"><i class="fa fa-check"></i><b>8.8.3</b> Increasing the power of your study</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="hypothesistesting.html"><a href="hypothesistesting.html#nhstmess"><i class="fa fa-check"></i><b>8.9</b> Some issues to consider</a>
<ul>
<li class="chapter" data-level="8.9.1" data-path="hypothesistesting.html"><a href="hypothesistesting.html#neyman-versus-fisher"><i class="fa fa-check"></i><b>8.9.1</b> Neyman versus Fisher</a></li>
<li class="chapter" data-level="8.9.2" data-path="hypothesistesting.html"><a href="hypothesistesting.html#bayesians-versus-frequentists"><i class="fa fa-check"></i><b>8.9.2</b> Bayesians versus frequentists</a></li>
<li class="chapter" data-level="8.9.3" data-path="hypothesistesting.html"><a href="hypothesistesting.html#traps"><i class="fa fa-check"></i><b>8.9.3</b> Traps</a></li>
</ul></li>
<li class="chapter" data-level="8.10" data-path="hypothesistesting.html"><a href="hypothesistesting.html#summary-4"><i class="fa fa-check"></i><b>8.10</b> Summary</a></li>
</ul></li>
<li class="part"><span><b>STATISTICAL TOOLS</b></span></li>
<li class="part"><span><b>BAYESIAN STATISTICS</b></span></li>
<li class="chapter" data-level="9" data-path="bayes.html"><a href="bayes.html"><i class="fa fa-check"></i><b>9</b> Introduction to Bayesian statistics</a>
<ul>
<li class="chapter" data-level="9.1" data-path="bayes.html"><a href="bayes.html#basicbayes"><i class="fa fa-check"></i><b>9.1</b> Probabilistic reasoning by rational agents</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="bayes.html"><a href="bayes.html#priors-what-you-believed-before"><i class="fa fa-check"></i><b>9.1.1</b> Priors: what you believed before</a></li>
<li class="chapter" data-level="9.1.2" data-path="bayes.html"><a href="bayes.html#likelihoods-theories-about-the-data"><i class="fa fa-check"></i><b>9.1.2</b> Likelihoods: theories about the data</a></li>
<li class="chapter" data-level="9.1.3" data-path="bayes.html"><a href="bayes.html#the-joint-probability-of-data-and-hypothesis"><i class="fa fa-check"></i><b>9.1.3</b> The joint probability of data and hypothesis</a></li>
<li class="chapter" data-level="9.1.4" data-path="bayes.html"><a href="bayes.html#updating-beliefs-using-bayes-rule"><i class="fa fa-check"></i><b>9.1.4</b> Updating beliefs using Bayes’ rule</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="bayesianhypothesistests.html"><a href="bayesianhypothesistests.html"><i class="fa fa-check"></i><b>10</b> Bayesian hypothesis tests</a>
<ul>
<li class="chapter" data-level="10.1" data-path="bayesianhypothesistests.html"><a href="bayesianhypothesistests.html#the-bayes-factor"><i class="fa fa-check"></i><b>10.1</b> The Bayes factor</a></li>
<li class="chapter" data-level="10.2" data-path="bayesianhypothesistests.html"><a href="bayesianhypothesistests.html#interpreting-bayes-factors"><i class="fa fa-check"></i><b>10.2</b> Interpreting Bayes factors</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="whybayes.html"><a href="whybayes.html"><i class="fa fa-check"></i><b>11</b> Why be a Bayesian?</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Learning Statistics with CogStat</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="bayes" class="section level1 hasAnchor" number="9">
<h1><span class="header-section-number">Chapter 9</span> Introduction to Bayesian statistics<a href="bayes.html#bayes" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<blockquote>
<p><em>In our reasonings concerning matter of fact, there are all imaginable degrees of assurance, from the highest certainty to the lowest species of moral evidence. A wise man, therefore, proportions his belief to the evidence.</em>
– David Hume<a href="#fn43" class="footnote-ref" id="fnref43"><sup>43</sup></a>.</p>
</blockquote>
<p>The ideas I’ve presented to you in this book describe inferential statistics from the frequentist perspective. I’m not alone in doing this. In fact, almost every textbook given to undergraduate psychology students presents the opinions of the frequentist statistician as <em>the</em> theory of inferential statistics, the one true way to do things. I have taught this way for practical reasons. The frequentist view of statistics dominated the academic field of statistics for most of the 20th century, and this dominance is even more extreme among applied scientists. It was and is current practice among psychologists to use frequentist methods. Because frequentist methods are ubiquitous in scientific papers, every student of statistics needs to understand those methods, otherwise they will be unable to make sense of what those papers are saying! Unfortunately – in my opinion at least – the current practice in psychology is often misguided, and the reliance on frequentist methods is partly to blame. In this chapter I explain why I think this, and provide an introduction to Bayesian statistics, an approach that I think is generally superior to the orthodox approach.</p>
<p>This chapter comes in two parts. In Sections <a href="bayes.html#basicbayes">9.1</a> through <a href="whybayes.html#whybayes">11</a> I talk about what Bayesian statistics are all about, covering the basic mathematical rules for how it works as well as an explanation for why I think the Bayesian approach is so useful. Afterwards, I provide a brief overview of how you can do Bayesian versions of chi-square tests (Section <a href="#bayescontingency"><strong>??</strong></a>), <span class="math inline">\(t\)</span>-tests (Section <a href="#ttestbf"><strong>??</strong></a>), regression (Section <a href="#bayesregression"><strong>??</strong></a>) and ANOVA (Section <a href="#bayesanova"><strong>??</strong></a>).</p>
<div id="basicbayes" class="section level2 hasAnchor" number="9.1">
<h2><span class="header-section-number">9.1</span> Probabilistic reasoning by rational agents<a href="bayes.html#basicbayes" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>From a Bayesian perspective, statistical inference is all about <em>belief revision</em>. I start out with a set of candidate hypotheses <span class="math inline">\(h\)</span> about the world. I don’t know which of these hypotheses is true, but do I have some beliefs about which hypotheses are plausible and which are not. When I observe the data <span class="math inline">\(d\)</span>, I have to revise those beliefs. If the data are consistent with a hypothesis, my belief in that hypothesis is strengthened. If the data inconsistent with the hypothesis, my belief in that hypothesis is weakened. That’s it! At the end of this section I’ll give a precise description of how Bayesian reasoning works, but first I want to work through a simple example in order to introduce the key ideas. Consider the following reasoning problem:</p>
<blockquote>
<p><em>I’m carrying an umbrella. Do you think it will rain?</em></p>
</blockquote>
<p>In this problem, I have presented you with a single piece of data (<span class="math inline">\(d =\)</span> I’m carrying the umbrella), and I’m asking you to tell me your beliefs about whether it’s raining. You have two possible <strong><em>hypotheses</em></strong>, <span class="math inline">\(h\)</span>: either it rains today or it does not. How should you solve this problem?</p>
<div id="priors-what-you-believed-before" class="section level3 hasAnchor" number="9.1.1">
<h3><span class="header-section-number">9.1.1</span> Priors: what you believed before<a href="bayes.html#priors-what-you-believed-before" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The first thing you need to do ignore what I told you about the umbrella, and write down your pre-existing beliefs about rain. This is important: if you want to be honest about how your beliefs have been revised in the light of new evidence, then you <em>must</em> say something about what you believed before those data appeared! So, what might you believe about whether it will rain today? You probably know that I live in Australia, and that much of Australia is hot and dry. And in fact you’re right: the city of Adelaide where I live has a Mediterranean climate, very similar to southern California, southern Europe or northern Africa. I’m writing this in January, and so you can assume it’s the middle of summer. In fact, you might have decided to take a quick look on Wikipedia<a href="#fn44" class="footnote-ref" id="fnref44"><sup>44</sup></a> and discovered that Adelaide gets an average of 4.4 days of rain across the 31 days of January. Without knowing anything else, you might conclude that the probability of January rain in Adelaide is about 15%, and the probability of a dry day is 85%. If this is really what you believe about Adelaide rainfall (and now that I’ve told it to you, I’m betting that this really <em>is</em> what you believe) then what I have written here is your <strong><em>prior distribution</em></strong>, written <span class="math inline">\(P(h)\)</span>:</p>
<table>
<thead>
<tr>
<th style="text-align:left;">
Hypothesis
</th>
<th style="text-align:left;">
Degree of Belief
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Rainy day
</td>
<td style="text-align:left;">
0.15
</td>
</tr>
<tr>
<td style="text-align:left;">
Dry day
</td>
<td style="text-align:left;">
0.85
</td>
</tr>
</tbody>
</table>
</div>
<div id="likelihoods-theories-about-the-data" class="section level3 hasAnchor" number="9.1.2">
<h3><span class="header-section-number">9.1.2</span> Likelihoods: theories about the data<a href="bayes.html#likelihoods-theories-about-the-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To solve the reasoning problem, you need a theory about my behaviour. When does Dan carry an umbrella? You might guess that I’m not a complete idiot,<a href="#fn45" class="footnote-ref" id="fnref45"><sup>45</sup></a> and I try to carry umbrellas only on rainy days. On the other hand, you also know that I have young kids, and you wouldn’t be all that surprised to know that I’m pretty forgetful about this sort of thing. Let’s suppose that on rainy days I remember my umbrella about 30% of the time (I really am awful at this). But let’s say that on dry days I’m only about 5% likely to be carrying an umbrella. So you might write out a little table like this:</p>
<table>
<thead>
<tr>
<th style="text-align:left;">
Hypothesis
</th>
<th style="text-align:left;">
Umbrella
</th>
<th style="text-align:left;">
No umbrella
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Rainy day
</td>
<td style="text-align:left;">
0.30
</td>
<td style="text-align:left;">
0.70
</td>
</tr>
<tr>
<td style="text-align:left;">
Dry day
</td>
<td style="text-align:left;">
0.05
</td>
<td style="text-align:left;">
0.95
</td>
</tr>
</tbody>
</table>
<p>It’s important to remember that each cell in this table describes your beliefs about what data <span class="math inline">\(d\)</span> will be observed, <em>given</em> the truth of a particular hypothesis <span class="math inline">\(h\)</span>. This “conditional probability” is written <span class="math inline">\(P(d|h)\)</span>, which you can read as “the probability of <span class="math inline">\(d\)</span> given <span class="math inline">\(h\)</span>”. In Bayesian statistics, this is referred to as <strong><em>likelihood</em></strong> of data <span class="math inline">\(d\)</span> given hypothesis <span class="math inline">\(h\)</span>.<a href="#fn46" class="footnote-ref" id="fnref46"><sup>46</sup></a></p>
</div>
<div id="the-joint-probability-of-data-and-hypothesis" class="section level3 hasAnchor" number="9.1.3">
<h3><span class="header-section-number">9.1.3</span> The joint probability of data and hypothesis<a href="bayes.html#the-joint-probability-of-data-and-hypothesis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>At this point, all the elements are in place. Having written down the priors and the likelihood, you have all the information you need to do Bayesian reasoning. The question now becomes, <em>how</em> do we use this information? As it turns out, there’s a very simple equation that we can use here, but it’s important that you understand why we use it, so I’m going to try to build it up from more basic ideas.</p>
<p>Let’s start out with one of the rules of probability theory. I listed it way back in Table <a href="probability.html#tab:probrules">6.1</a>, but I didn’t make a big deal out of it at the time and you probably ignored it. The rule in question is the one that talks about the probability that <em>two</em> things are true. In our example, you might want to calculate the probability that today is rainy (i.e., hypothesis <span class="math inline">\(h\)</span> is true) <em>and</em> I’m carrying an umbrella (i.e., data <span class="math inline">\(d\)</span> is observed). The <strong><em>joint probability</em></strong> of the hypothesis and the data is written <span class="math inline">\(P(d,h)\)</span>, and you can calculate it by multiplying the prior <span class="math inline">\(P(h)\)</span> by the likelihood <span class="math inline">\(P(d|h)\)</span>. Mathematically, we say that:
<span class="math display">\[
P(d,h) = P(d|h) P(h)
\]</span></p>
<p>So, what is the probability that today is a rainy day <em>and</em> I remember to carry an umbrella? As we discussed earlier, the prior tells us that the probability of a rainy day is 15%, and the likelihood tells us that the probability of me remembering my umbrella on a rainy day is 30%. So the probability that both of these things are true is calculated by multiplying the two:</p>
<p><span class="math display">\[
\begin{array}
P(\mbox{rainy}, \mbox{umbrella}) &amp; = &amp; P(\mbox{umbrella} | \mbox{rainy}) \times P(\mbox{rainy}) \\
&amp; = &amp; 0.30 \times 0.15 \\
&amp; = &amp; 0.045
\end{array}
\]</span></p>
<p>In other words, before being told anything about what actually happened, you think that there is a 4.5% probability that today will be a rainy day and that I will remember an umbrella. However, there are of course <em>four</em> possible things that could happen, right? So let’s repeat the exercise for all four. If we do that, we end up with the following table:</p>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
Umbrella
</th>
<th style="text-align:left;">
No-umbrella
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Rainy
</td>
<td style="text-align:left;">
0.045
</td>
<td style="text-align:left;">
0.105
</td>
</tr>
<tr>
<td style="text-align:left;">
Dry
</td>
<td style="text-align:left;">
0.0425
</td>
<td style="text-align:left;">
0.8075
</td>
</tr>
</tbody>
</table>
<p>This table captures all the information about which of the four possibilities are likely. To really get the full picture, though, it helps to add the row totals and column totals. That gives us this table:</p>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
Umbrella
</th>
<th style="text-align:left;">
No-umbrella
</th>
<th style="text-align:left;">
Total
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Rainy
</td>
<td style="text-align:left;">
0.0450
</td>
<td style="text-align:left;">
0.1050
</td>
<td style="text-align:left;">
0.15
</td>
</tr>
<tr>
<td style="text-align:left;">
Dry
</td>
<td style="text-align:left;">
0.0425
</td>
<td style="text-align:left;">
0.8075
</td>
<td style="text-align:left;">
0.85
</td>
</tr>
<tr>
<td style="text-align:left;">
Total
</td>
<td style="text-align:left;">
0.0875
</td>
<td style="text-align:left;">
0.9125
</td>
<td style="text-align:left;">
1
</td>
</tr>
</tbody>
</table>
<p>This is a very useful table, so it’s worth taking a moment to think about what all these numbers are telling us. First, notice that the row sums aren’t telling us anything new at all. For example, the first row tells us that if we ignore all this umbrella business, the chance that today will be a rainy day is 15%. That’s not surprising, of course: that’s our prior. The important thing isn’t the number itself: rather, the important thing is that it gives us some confidence that our calculations are sensible! Now take a look at the column sums, and notice that they tell us something that we haven’t explicitly stated yet. In the same way that the row sums tell us the probability of rain, the column sums tell us the probability of me carrying an umbrella. Specifically, the first column tells us that on average (i.e., ignoring whether it’s a rainy day or not), the probability of me carrying an umbrella is 8.75%. Finally, notice that when we sum across all four logically-possible events, everything adds up to 1. In other words, what we have written down is a proper probability distribution defined over all possible combinations of data and hypothesis.</p>
<p>Now, because this table is so useful, I want to make sure you understand what all the elements correspond to, and how they written:</p>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
Umbrella
</th>
<th style="text-align:left;">
No-umbrella
</th>
<th style="text-align:left;">
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Rainy
</td>
<td style="text-align:left;">
<span class="math inline">\(P\)</span>(Umbrella, Rainy)
</td>
<td style="text-align:left;">
<span class="math inline">\(P\)</span>(No-umbrella, Rainy)
</td>
<td style="text-align:left;">
<span class="math inline">\(P\)</span>(Rainy)
</td>
</tr>
<tr>
<td style="text-align:left;">
Dry
</td>
<td style="text-align:left;">
<span class="math inline">\(P\)</span>(Umbrella, Dry)
</td>
<td style="text-align:left;">
<span class="math inline">\(P\)</span>(No-umbrella, Dry)
</td>
<td style="text-align:left;">
<span class="math inline">\(P\)</span>(Dry)
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
<span class="math inline">\(P\)</span>(Umbrella)
</td>
<td style="text-align:left;">
<span class="math inline">\(P\)</span>(No-umbrella)
</td>
<td style="text-align:left;">
</td>
</tr>
</tbody>
</table>
<p>Finally, let’s use “proper” statistical notation. In the rainy day problem, the data corresponds to the observation that I do or do not have an umbrella. So we’ll let <span class="math inline">\(d_1\)</span> refer to the possibility that you observe me carrying an umbrella, and <span class="math inline">\(d_2\)</span> refers to you observing me not carrying one. Similarly, <span class="math inline">\(h_1\)</span> is your hypothesis that today is rainy, and <span class="math inline">\(h_2\)</span> is the hypothesis that it is not. Using this notation, the table looks like this:</p>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
<span class="math inline">\(d_1\)</span>
</th>
<th style="text-align:left;">
<span class="math inline">\(d_2\)</span>
</th>
<th style="text-align:left;">
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<span class="math inline">\(h_1\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(P(h_1, d_1)\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(P(h_1, d_2)\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(P(h_1)\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(h_2\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(P(h_2, d_1)\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(P(h_2, d_2)\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(P(h_2)\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
<span class="math inline">\(P(d_1)\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(P(d_2)\)</span>
</td>
<td style="text-align:left;">
</td>
</tr>
</tbody>
</table>
</div>
<div id="updating-beliefs-using-bayes-rule" class="section level3 hasAnchor" number="9.1.4">
<h3><span class="header-section-number">9.1.4</span> Updating beliefs using Bayes’ rule<a href="bayes.html#updating-beliefs-using-bayes-rule" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The table we laid out in the last section is a very powerful tool for solving the rainy day problem, because it considers all four logical possibilities and states exactly how confident you are in each of them before being given any data. It’s now time to consider what happens to our beliefs when we are actually given the data. In the rainy day problem, you are told that I really <em>am</em> carrying an umbrella. This is something of a surprising event: according to our table, the probability of me carrying an umbrella is only 8.75%. But that makes sense, right? A guy carrying an umbrella on a summer day in a hot dry city is pretty unusual, and so you really weren’t expecting that. Nevertheless, the problem tells you that it is true. No matter how unlikely you thought it was, you must now adjust your beliefs to accommodate the fact that you now <em>know</em> that I have an umbrella.<a href="#fn47" class="footnote-ref" id="fnref47"><sup>47</sup></a> To reflect this new knowledge, our <em>revised</em> table must have the following numbers:</p>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
Umbrella
</th>
<th style="text-align:left;">
No-umbrella
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Rainy
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
Dry
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
Total
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
0
</td>
</tr>
</tbody>
</table>
<p>In other words, the facts have eliminated any possibility of “no umbrella”, so we have to put zeros into any cell in the table that implies that I’m not carrying an umbrella. Also, you know for a fact that I am carrying an umbrella, so the column sum on the left must be 1 to correctly describe the fact that <span class="math inline">\(P(\mbox{umbrella})=1\)</span>.</p>
<p>What two numbers should we put in the empty cells? Again, let’s not worry about the maths, and instead think about our intuitions. When we wrote out our table the first time, it turned out that those two cells had almost identical numbers, right? We worked out that the joint probability of “rain and umbrella” was 4.5%, and the joint probability of “dry and umbrella” was 4.25%. In other words, before I told you that I am in fact carrying an umbrella, you’d have said that these two events were almost identical in probability, yes? But notice that <em>both</em> of these possibilities are consistent with the fact that I actually am carrying an umbrella. From the perspective of these two possibilities, very little has changed. I hope you’d agree that it’s <em>still</em> true that these two possibilities are equally plausible. So what we expect to see in our final table is some numbers that preserve the fact that “rain and umbrella” is <em>slightly</em> more plausible than “dry and umbrella”, while still ensuring that numbers in the table add up. Something like this, perhaps?</p>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
Umbrella
</th>
<th style="text-align:left;">
No-umbrella
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Rainy
</td>
<td style="text-align:left;">
0.514
</td>
<td style="text-align:left;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
Dry
</td>
<td style="text-align:left;">
0.486
</td>
<td style="text-align:left;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
Total
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
0
</td>
</tr>
</tbody>
</table>
<p>What this table is telling you is that, after being told that I’m carrying an umbrella, you believe that there’s a 51.4% chance that today will be a rainy day, and a 48.6% chance that it won’t. That’s the answer to our problem! The <strong><em>posterior probability</em></strong> of rain <span class="math inline">\(P(h|d)\)</span> given that I am carrying an umbrella is 51.4%</p>
<p>How did I calculate these numbers? You can probably guess. To work out that there was a 0.514 probability of “rain”, all I did was take the 0.045 probability of “rain and umbrella” and divide it by the 0.0875 chance of “umbrella”. This produces a table that satisfies our need to have everything sum to 1, and our need not to interfere with the relative plausibility of the two events that are actually consistent with the data. To say the same thing using fancy statistical jargon, what I’ve done here is divide the joint probability of the hypothesis and the data <span class="math inline">\(P(d,h)\)</span> by the <strong><em>marginal probability</em></strong> of the data <span class="math inline">\(P(d)\)</span>, and this is what gives us the posterior probability of the hypothesis <em>given</em> that we know the data have been observed. To write this as an equation:<a href="#fn48" class="footnote-ref" id="fnref48"><sup>48</sup></a>
<span class="math display">\[
P(h | d) = \frac{P(d,h)}{P(d)}
\]</span></p>
<p>However, remember what I said at the start of the last section, namely that the joint probability <span class="math inline">\(P(d,h)\)</span> is calculated by multiplying the prior <span class="math inline">\(P(h)\)</span> by the likelihood <span class="math inline">\(P(d|h)\)</span>. In real life, the things we actually know how to write down are the priors and the likelihood, so let’s substitute those back into the equation. This gives us the following formula for the posterior probability:</p>
<p><span class="math display">\[
P(h | d) = \frac{P(d|h) P(h)}{P(d)}
\]</span></p>
<p>And this formula, folks, is known as <strong><em>Bayes’ rule</em></strong>. It describes how a learner starts out with prior beliefs about the plausibility of different hypotheses, and tells you how those beliefs should be revised in the face of data. In the Bayesian paradigm, all statistical inference flows from this one simple rule.</p>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="43">
<li id="fn43"><p><a href="http://en.wikiquote.org/wiki/David_Hume" class="uri">http://en.wikiquote.org/wiki/David_Hume</a><a href="bayes.html#fnref43" class="footnote-back">↩︎</a></p></li>
<li id="fn44"><p><a href="http://en.wikipedia.org/wiki/Climate_of_Adelaide" class="uri">http://en.wikipedia.org/wiki/Climate_of_Adelaide</a><a href="bayes.html#fnref44" class="footnote-back">↩︎</a></p></li>
<li id="fn45"><p>It’s a leap of faith, I know, but let’s run with it okay?<a href="bayes.html#fnref45" class="footnote-back">↩︎</a></p></li>
<li id="fn46"><p>Um. I hate to bring this up, but some statisticians would object to me using the word “likelihood” here. The problem is that the word “likelihood” has a very specific meaning in frequentist statistics, and it’s not quite the same as what it means in Bayesian statistics. As far as I can tell, Bayesians didn’t originally have any agreed upon name for the likelihood, and so it became common practice for people to use the frequentist terminology. This wouldn’t have been a problem, except for the fact that the way that Bayesians use the word turns out to be quite different to the way frequentists do. This isn’t the place for yet another lengthy history lesson, but to put it crudely: when a Bayesian says “<em>a</em> likelihood function” they’re usually referring one of the <em>rows</em> of the table. When a frequentist says the same thing, they’re referring to the same table, but to them “<em>a</em> likelihood function” almost always refers to one of the <em>columns</em>. This distinction matters in some contexts, but it’s not important for our purposes.<a href="bayes.html#fnref46" class="footnote-back">↩︎</a></p></li>
<li id="fn47"><p>If we were being a bit more sophisticated, we could extend the example to accommodate the possibility that I’m lying about the umbrella. But let’s keep things simple, shall we?<a href="bayes.html#fnref47" class="footnote-back">↩︎</a></p></li>
<li id="fn48"><p>You might notice that this equation is actually a restatement of the same basic rule I listed at the start of the last section. If you multiply both sides of the equation by <span class="math inline">\(P(d)\)</span>, then you get <span class="math inline">\(P(d) P(h| d) = P(d,h)\)</span>, which is the rule for how joint probabilities are calculated. So I’m not actually introducing any “new” rules here, I’m just using the same rule in a different way.<a href="bayes.html#fnref48" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="hypothesistesting.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bayesianhypothesistests.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"number_sections": true,
"fig_caption": true
},
"toc_depth": 2,
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

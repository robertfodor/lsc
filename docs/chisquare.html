<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 Categorical data analysis | Learning Statistics with CogStat</title>
  <meta name="description" content="Chapter 9 Categorical data analysis | Learning Statistics with CogStat covers the contents of an introductory statistics class, as typically taught to undergraduate psychology students based on Danielle Navarro’s original Learning Statistics with R with a focus on automatic statistical analysis performed in CogStat." />
  <meta name="generator" content="bookdown 0.29 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 Categorical data analysis | Learning Statistics with CogStat" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Chapter 9 Categorical data analysis | Learning Statistics with CogStat covers the contents of an introductory statistics class, as typically taught to undergraduate psychology students based on Danielle Navarro’s original Learning Statistics with R with a focus on automatic statistical analysis performed in CogStat." />
  <meta name="github-repo" content="https://github.com/robertfodor/lsc" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Categorical data analysis | Learning Statistics with CogStat" />
  
  <meta name="twitter:description" content="Chapter 9 Categorical data analysis | Learning Statistics with CogStat covers the contents of an introductory statistics class, as typically taught to undergraduate psychology students based on Danielle Navarro’s original Learning Statistics with R with a focus on automatic statistical analysis performed in CogStat." />
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="hypothesistesting.html"/>
<link rel="next" href="ttest.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Learning Statistics with CogStat</a></li>

<li class="divider"></li>
<li class="part"><span><b>INTRODUCTIONS</b></span></li>
<li class="chapter" data-level="1" data-path="whywhywhy.html"><a href="whywhywhy.html"><i class="fa fa-check"></i><b>1</b> Why do we learn statistics?</a></li>
<li class="chapter" data-level="2" data-path="cogstat_intro.html"><a href="cogstat_intro.html"><i class="fa fa-check"></i><b>2</b> An Introduction to CogStat</a>
<ul>
<li class="chapter" data-level="2.1" data-path="cogstat_intro.html"><a href="cogstat_intro.html#foreword_cogstat"><i class="fa fa-check"></i><b>2.1</b> How CogStat came about</a></li>
<li class="chapter" data-level="2.2" data-path="cogstat_intro.html"><a href="cogstat_intro.html#autostat"><i class="fa fa-check"></i><b>2.2</b> An introduction to automatic statistical analysis</a></li>
<li class="chapter" data-level="2.3" data-path="cogstat_intro.html"><a href="cogstat_intro.html#gettingstarted"><i class="fa fa-check"></i><b>2.3</b> Getting started with CogStat</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="cogstat_intro.html"><a href="cogstat_intro.html#installing-cogstat"><i class="fa fa-check"></i><b>2.3.1</b> Installing CogStat</a></li>
<li class="chapter" data-level="2.3.2" data-path="cogstat_intro.html"><a href="cogstat_intro.html#loading-data"><i class="fa fa-check"></i><b>2.3.2</b> Loading data</a></li>
<li class="chapter" data-level="2.3.3" data-path="cogstat_intro.html"><a href="cogstat_intro.html#saving-and-exporting-your-results"><i class="fa fa-check"></i><b>2.3.3</b> Saving and exporting your results</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="cogstat_intro.html"><a href="cogstat_intro.html#how-to-use-this-book"><i class="fa fa-check"></i><b>2.4</b> How to use this book</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="researchdesign.html"><a href="researchdesign.html"><i class="fa fa-check"></i><b>3</b> A brief introduction to research design</a>
<ul>
<li class="chapter" data-level="3.1" data-path="researchdesign.html"><a href="researchdesign.html#measurement"><i class="fa fa-check"></i><b>3.1</b> Introduction to psychological measurement</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="researchdesign.html"><a href="researchdesign.html#some-thoughts-about-psychological-measurement"><i class="fa fa-check"></i><b>3.1.1</b> Some thoughts about psychological measurement</a></li>
<li class="chapter" data-level="3.1.2" data-path="researchdesign.html"><a href="researchdesign.html#operationalisation-defining-your-measurement"><i class="fa fa-check"></i><b>3.1.2</b> Operationalisation: defining your measurement</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="researchdesign.html"><a href="researchdesign.html#scales"><i class="fa fa-check"></i><b>3.2</b> Scales of measurement</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="researchdesign.html"><a href="researchdesign.html#nominalscale"><i class="fa fa-check"></i><b>3.2.1</b> Nominal scale</a></li>
<li class="chapter" data-level="3.2.2" data-path="researchdesign.html"><a href="researchdesign.html#ordinalscale"><i class="fa fa-check"></i><b>3.2.2</b> Ordinal scale</a></li>
<li class="chapter" data-level="3.2.3" data-path="researchdesign.html"><a href="researchdesign.html#intervalscale"><i class="fa fa-check"></i><b>3.2.3</b> Interval scale</a></li>
<li class="chapter" data-level="3.2.4" data-path="researchdesign.html"><a href="researchdesign.html#ratioscale"><i class="fa fa-check"></i><b>3.2.4</b> Ratio scale</a></li>
<li class="chapter" data-level="3.2.5" data-path="researchdesign.html"><a href="researchdesign.html#continuousdiscrete"><i class="fa fa-check"></i><b>3.2.5</b> Continuous versus discrete variables</a></li>
<li class="chapter" data-level="3.2.6" data-path="researchdesign.html"><a href="researchdesign.html#likertscale"><i class="fa fa-check"></i><b>3.2.6</b> Some complexities: the Likert scale</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="researchdesign.html"><a href="researchdesign.html#reliability"><i class="fa fa-check"></i><b>3.3</b> Assessing the reliability of a measurement</a></li>
<li class="chapter" data-level="3.4" data-path="researchdesign.html"><a href="researchdesign.html#ivdv"><i class="fa fa-check"></i><b>3.4</b> The “role” of variables: predictors and outcomes</a></li>
<li class="chapter" data-level="3.5" data-path="researchdesign.html"><a href="researchdesign.html#researchdesigns"><i class="fa fa-check"></i><b>3.5</b> Experimental and non-experimental research</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="researchdesign.html"><a href="researchdesign.html#experimental-research"><i class="fa fa-check"></i><b>3.5.1</b> Experimental research</a></li>
<li class="chapter" data-level="3.5.2" data-path="researchdesign.html"><a href="researchdesign.html#non-experimental-research"><i class="fa fa-check"></i><b>3.5.2</b> Non-experimental research</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="researchdesign.html"><a href="researchdesign.html#validity"><i class="fa fa-check"></i><b>3.6</b> Assessing the validity of a study</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="researchdesign.html"><a href="researchdesign.html#internal-validity"><i class="fa fa-check"></i><b>3.6.1</b> Internal validity</a></li>
<li class="chapter" data-level="3.6.2" data-path="researchdesign.html"><a href="researchdesign.html#external-validity"><i class="fa fa-check"></i><b>3.6.2</b> External validity</a></li>
<li class="chapter" data-level="3.6.3" data-path="researchdesign.html"><a href="researchdesign.html#construct-validity"><i class="fa fa-check"></i><b>3.6.3</b> Construct validity</a></li>
<li class="chapter" data-level="3.6.4" data-path="researchdesign.html"><a href="researchdesign.html#face-validity"><i class="fa fa-check"></i><b>3.6.4</b> Face validity</a></li>
<li class="chapter" data-level="3.6.5" data-path="researchdesign.html"><a href="researchdesign.html#ecological-validity"><i class="fa fa-check"></i><b>3.6.5</b> Ecological validity</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="researchdesign.html"><a href="researchdesign.html#confounds-artefacts-and-other-threats-to-validity"><i class="fa fa-check"></i><b>3.7</b> Confounds, artefacts and other threats to validity</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="researchdesign.html"><a href="researchdesign.html#history-effects"><i class="fa fa-check"></i><b>3.7.1</b> History effects</a></li>
<li class="chapter" data-level="3.7.2" data-path="researchdesign.html"><a href="researchdesign.html#maturation-effects"><i class="fa fa-check"></i><b>3.7.2</b> Maturation effects</a></li>
<li class="chapter" data-level="3.7.3" data-path="researchdesign.html"><a href="researchdesign.html#repeated-testing-effects"><i class="fa fa-check"></i><b>3.7.3</b> Repeated testing effects</a></li>
<li class="chapter" data-level="3.7.4" data-path="researchdesign.html"><a href="researchdesign.html#selection-bias"><i class="fa fa-check"></i><b>3.7.4</b> Selection bias</a></li>
<li class="chapter" data-level="3.7.5" data-path="researchdesign.html"><a href="researchdesign.html#differentialattrition"><i class="fa fa-check"></i><b>3.7.5</b> Differential attrition</a></li>
<li class="chapter" data-level="3.7.6" data-path="researchdesign.html"><a href="researchdesign.html#non-response-bias"><i class="fa fa-check"></i><b>3.7.6</b> Non-response bias</a></li>
<li class="chapter" data-level="3.7.7" data-path="researchdesign.html"><a href="researchdesign.html#regression-to-the-mean"><i class="fa fa-check"></i><b>3.7.7</b> Regression to the mean</a></li>
<li class="chapter" data-level="3.7.8" data-path="researchdesign.html"><a href="researchdesign.html#experimenter-bias"><i class="fa fa-check"></i><b>3.7.8</b> Experimenter bias</a></li>
<li class="chapter" data-level="3.7.9" data-path="researchdesign.html"><a href="researchdesign.html#demand-effects-and-reactivity"><i class="fa fa-check"></i><b>3.7.9</b> Demand effects and reactivity</a></li>
<li class="chapter" data-level="3.7.10" data-path="researchdesign.html"><a href="researchdesign.html#placebo-effects"><i class="fa fa-check"></i><b>3.7.10</b> Placebo effects</a></li>
<li class="chapter" data-level="3.7.11" data-path="researchdesign.html"><a href="researchdesign.html#situation-measurement-and-subpopulation-effects"><i class="fa fa-check"></i><b>3.7.11</b> Situation, measurement and subpopulation effects</a></li>
<li class="chapter" data-level="3.7.12" data-path="researchdesign.html"><a href="researchdesign.html#fraud-deception-and-self-deception"><i class="fa fa-check"></i><b>3.7.12</b> Fraud, deception and self-deception</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="researchdesign.html"><a href="researchdesign.html#summary"><i class="fa fa-check"></i><b>3.8</b> Summary</a></li>
</ul></li>
<li class="part"><span><b>DESCRIPTIVE STATISTICS</b></span></li>
<li class="chapter" data-level="4" data-path="exploringavariable.html"><a href="exploringavariable.html"><i class="fa fa-check"></i><b>4</b> Exploring a single variable</a>
<ul>
<li class="chapter" data-level="4.1" data-path="exploringavariable.html"><a href="exploringavariable.html#centraltendency"><i class="fa fa-check"></i><b>4.1</b> Measures of central tendency</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="exploringavariable.html"><a href="exploringavariable.html#mean"><i class="fa fa-check"></i><b>4.1.1</b> The mean</a></li>
<li class="chapter" data-level="4.1.2" data-path="exploringavariable.html"><a href="exploringavariable.html#median"><i class="fa fa-check"></i><b>4.1.2</b> The median</a></li>
<li class="chapter" data-level="4.1.3" data-path="exploringavariable.html"><a href="exploringavariable.html#mean-or-median-whats-the-difference"><i class="fa fa-check"></i><b>4.1.3</b> Mean or median? What’s the difference?</a></li>
<li class="chapter" data-level="4.1.4" data-path="exploringavariable.html"><a href="exploringavariable.html#trimmedmean"><i class="fa fa-check"></i><b>4.1.4</b> Trimmed mean</a></li>
<li class="chapter" data-level="4.1.5" data-path="exploringavariable.html"><a href="exploringavariable.html#mode"><i class="fa fa-check"></i><b>4.1.5</b> Mode</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="exploringavariable.html"><a href="exploringavariable.html#var"><i class="fa fa-check"></i><b>4.2</b> Measures of variability</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="exploringavariable.html"><a href="exploringavariable.html#range"><i class="fa fa-check"></i><b>4.2.1</b> Range</a></li>
<li class="chapter" data-level="4.2.2" data-path="exploringavariable.html"><a href="exploringavariable.html#IQR"><i class="fa fa-check"></i><b>4.2.2</b> Interquartile range</a></li>
<li class="chapter" data-level="4.2.3" data-path="exploringavariable.html"><a href="exploringavariable.html#aad"><i class="fa fa-check"></i><b>4.2.3</b> Mean absolute deviation</a></li>
<li class="chapter" data-level="4.2.4" data-path="exploringavariable.html"><a href="exploringavariable.html#variance"><i class="fa fa-check"></i><b>4.2.4</b> Variance</a></li>
<li class="chapter" data-level="4.2.5" data-path="exploringavariable.html"><a href="exploringavariable.html#sd"><i class="fa fa-check"></i><b>4.2.5</b> Standard deviation</a></li>
<li class="chapter" data-level="4.2.6" data-path="exploringavariable.html"><a href="exploringavariable.html#mad"><i class="fa fa-check"></i><b>4.2.6</b> Median absolute deviation</a></li>
<li class="chapter" data-level="4.2.7" data-path="exploringavariable.html"><a href="exploringavariable.html#which-measure-to-use"><i class="fa fa-check"></i><b>4.2.7</b> Which measure to use?</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="exploringavariable.html"><a href="exploringavariable.html#skewnesskurtosis"><i class="fa fa-check"></i><b>4.3</b> Skewness and kurtosis</a></li>
<li class="chapter" data-level="4.4" data-path="exploringavariable.html"><a href="exploringavariable.html#zscore"><i class="fa fa-check"></i><b>4.4</b> Standard scores (<span class="math inline">\(z\)</span>-score)</a></li>
<li class="chapter" data-level="4.5" data-path="exploringavariable.html"><a href="exploringavariable.html#summary-descriptives"><i class="fa fa-check"></i><b>4.5</b> Summary: descriptives</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="correl.html"><a href="correl.html"><i class="fa fa-check"></i><b>5</b> Exploring a variable pair</a>
<ul>
<li class="chapter" data-level="5.1" data-path="correl.html"><a href="correl.html#the-strength-and-direction-of-a-relationship"><i class="fa fa-check"></i><b>5.1</b> The strength and direction of a relationship</a></li>
<li class="chapter" data-level="5.2" data-path="correl.html"><a href="correl.html#pearson"><i class="fa fa-check"></i><b>5.2</b> The correlation coefficient</a></li>
<li class="chapter" data-level="5.3" data-path="correl.html"><a href="correl.html#interpretingcorrelations"><i class="fa fa-check"></i><b>5.3</b> Interpreting a correlation</a></li>
<li class="chapter" data-level="5.4" data-path="correl.html"><a href="correl.html#spearman"><i class="fa fa-check"></i><b>5.4</b> Spearman’s rank correlations</a></li>
<li class="chapter" data-level="5.5" data-path="correl.html"><a href="correl.html#missingvaluespair"><i class="fa fa-check"></i><b>5.5</b> Missing values in pairwise calculations</a></li>
<li class="chapter" data-level="5.6" data-path="correl.html"><a href="correl.html#summary-1"><i class="fa fa-check"></i><b>5.6</b> Summary</a></li>
</ul></li>
<li class="part"><span><b>INFERENTIAL STATISTICS</b></span></li>
<li class="chapter" data-level="6" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>6</b> Probability and distributions</a>
<ul>
<li class="chapter" data-level="6.1" data-path="probability.html"><a href="probability.html#probabilitystats"><i class="fa fa-check"></i><b>6.1</b> How are probability and statistics different?</a></li>
<li class="chapter" data-level="6.2" data-path="probability.html"><a href="probability.html#probabilitymeaning"><i class="fa fa-check"></i><b>6.2</b> What does probability mean?</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="probability.html"><a href="probability.html#the-frequentist-view"><i class="fa fa-check"></i><b>6.2.1</b> The frequentist view</a></li>
<li class="chapter" data-level="6.2.2" data-path="probability.html"><a href="probability.html#the-bayesian-view"><i class="fa fa-check"></i><b>6.2.2</b> The Bayesian view</a></li>
<li class="chapter" data-level="6.2.3" data-path="probability.html"><a href="probability.html#whats-the-difference-and-who-is-right"><i class="fa fa-check"></i><b>6.2.3</b> What’s the difference? And who is right?</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="probability.html"><a href="probability.html#basicprobability"><i class="fa fa-check"></i><b>6.3</b> Basic probability theory</a></li>
<li class="chapter" data-level="6.4" data-path="probability.html"><a href="probability.html#distributions"><i class="fa fa-check"></i><b>6.4</b> Distributions</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="probability.html"><a href="probability.html#binomial"><i class="fa fa-check"></i><b>6.4.1</b> The binomial distribution</a></li>
<li class="chapter" data-level="6.4.2" data-path="probability.html"><a href="probability.html#normal"><i class="fa fa-check"></i><b>6.4.2</b> The normal distribution</a></li>
<li class="chapter" data-level="6.4.3" data-path="probability.html"><a href="probability.html#density"><i class="fa fa-check"></i><b>6.4.3</b> Probability density</a></li>
<li class="chapter" data-level="6.4.4" data-path="probability.html"><a href="probability.html#otherdists"><i class="fa fa-check"></i><b>6.4.4</b> Other useful distributions</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="probability.html"><a href="probability.html#summary-2"><i class="fa fa-check"></i><b>6.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="estimation.html"><a href="estimation.html"><i class="fa fa-check"></i><b>7</b> Population, sampling, estimation</a>
<ul>
<li class="chapter" data-level="7.1" data-path="estimation.html"><a href="estimation.html#srs"><i class="fa fa-check"></i><b>7.1</b> Samples, populations and sampling</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="estimation.html"><a href="estimation.html#pop"><i class="fa fa-check"></i><b>7.1.1</b> Defining a population</a></li>
<li class="chapter" data-level="7.1.2" data-path="estimation.html"><a href="estimation.html#simple-random-samples"><i class="fa fa-check"></i><b>7.1.2</b> Simple random samples</a></li>
<li class="chapter" data-level="7.1.3" data-path="estimation.html"><a href="estimation.html#most-samples-are-not-simple-random-samples"><i class="fa fa-check"></i><b>7.1.3</b> Most samples are not simple random samples</a></li>
<li class="chapter" data-level="7.1.4" data-path="estimation.html"><a href="estimation.html#how-much-does-it-matter-if-you-dont-have-a-simple-random-sample"><i class="fa fa-check"></i><b>7.1.4</b> How much does it matter if you don’t have a simple random sample?</a></li>
<li class="chapter" data-level="7.1.5" data-path="estimation.html"><a href="estimation.html#population-parameters-and-sample-statistics"><i class="fa fa-check"></i><b>7.1.5</b> Population parameters and sample statistics</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="estimation.html"><a href="estimation.html#lawlargenumbers"><i class="fa fa-check"></i><b>7.2</b> The law of large numbers</a></li>
<li class="chapter" data-level="7.3" data-path="estimation.html"><a href="estimation.html#samplesandclt"><i class="fa fa-check"></i><b>7.3</b> Sampling distributions and the central limit theorem</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="estimation.html"><a href="estimation.html#samplingdists"><i class="fa fa-check"></i><b>7.3.1</b> Sampling distribution of the mean</a></li>
<li class="chapter" data-level="7.3.2" data-path="estimation.html"><a href="estimation.html#sampling-distributions-exist-for-any-sample-statistic"><i class="fa fa-check"></i><b>7.3.2</b> Sampling distributions exist for any sample statistic!</a></li>
<li class="chapter" data-level="7.3.3" data-path="estimation.html"><a href="estimation.html#clt"><i class="fa fa-check"></i><b>7.3.3</b> The central limit theorem</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="estimation.html"><a href="estimation.html#pointestimates"><i class="fa fa-check"></i><b>7.4</b> Estimating population parameters</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="estimation.html"><a href="estimation.html#estimating-the-population-mean"><i class="fa fa-check"></i><b>7.4.1</b> Estimating the population mean</a></li>
<li class="chapter" data-level="7.4.2" data-path="estimation.html"><a href="estimation.html#estimating-the-population-standard-deviation"><i class="fa fa-check"></i><b>7.4.2</b> Estimating the population standard deviation</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="estimation.html"><a href="estimation.html#ci"><i class="fa fa-check"></i><b>7.5</b> Estimating a confidence interval</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="estimation.html"><a href="estimation.html#a-slight-mistake-in-the-formula"><i class="fa fa-check"></i><b>7.5.1</b> A slight mistake in the formula</a></li>
<li class="chapter" data-level="7.5.2" data-path="estimation.html"><a href="estimation.html#interpreting-a-confidence-interval"><i class="fa fa-check"></i><b>7.5.2</b> Interpreting a confidence interval</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="estimation.html"><a href="estimation.html#population-parameter-estimations-in-cogstat"><i class="fa fa-check"></i><b>7.6</b> Population parameter estimations in CogStat</a></li>
<li class="chapter" data-level="7.7" data-path="estimation.html"><a href="estimation.html#summary-3"><i class="fa fa-check"></i><b>7.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="hypothesistesting.html"><a href="hypothesistesting.html"><i class="fa fa-check"></i><b>8</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="8.1" data-path="hypothesistesting.html"><a href="hypothesistesting.html#hypotheses"><i class="fa fa-check"></i><b>8.1</b> A menagerie of hypotheses</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="hypothesistesting.html"><a href="hypothesistesting.html#research-hypotheses-versus-statistical-hypotheses"><i class="fa fa-check"></i><b>8.1.1</b> Research hypotheses versus statistical hypotheses</a></li>
<li class="chapter" data-level="8.1.2" data-path="hypothesistesting.html"><a href="hypothesistesting.html#null-hypotheses-and-alternative-hypotheses"><i class="fa fa-check"></i><b>8.1.2</b> Null hypotheses and alternative hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="hypothesistesting.html"><a href="hypothesistesting.html#errortypes"><i class="fa fa-check"></i><b>8.2</b> Two types of errors</a></li>
<li class="chapter" data-level="8.3" data-path="hypothesistesting.html"><a href="hypothesistesting.html#teststatistics"><i class="fa fa-check"></i><b>8.3</b> Test statistics and sampling distributions</a></li>
<li class="chapter" data-level="8.4" data-path="hypothesistesting.html"><a href="hypothesistesting.html#decisionmaking"><i class="fa fa-check"></i><b>8.4</b> Making decisions</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="hypothesistesting.html"><a href="hypothesistesting.html#critical-regions-and-critical-values"><i class="fa fa-check"></i><b>8.4.1</b> Critical regions and critical values</a></li>
<li class="chapter" data-level="8.4.2" data-path="hypothesistesting.html"><a href="hypothesistesting.html#a-note-on-statistical-significance"><i class="fa fa-check"></i><b>8.4.2</b> A note on statistical “significance”</a></li>
<li class="chapter" data-level="8.4.3" data-path="hypothesistesting.html"><a href="hypothesistesting.html#a-note-on-the-word-prove"><i class="fa fa-check"></i><b>8.4.3</b> A note on the word “prove”</a></li>
<li class="chapter" data-level="8.4.4" data-path="hypothesistesting.html"><a href="hypothesistesting.html#onesidedtests"><i class="fa fa-check"></i><b>8.4.4</b> The difference between one sided and two sided tests</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="hypothesistesting.html"><a href="hypothesistesting.html#pvalue"><i class="fa fa-check"></i><b>8.5</b> The <span class="math inline">\(p\)</span> value of a test</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="hypothesistesting.html"><a href="hypothesistesting.html#a-softer-view-of-decision-making"><i class="fa fa-check"></i><b>8.5.1</b> A softer view of decision making</a></li>
<li class="chapter" data-level="8.5.2" data-path="hypothesistesting.html"><a href="hypothesistesting.html#the-probability-of-extreme-data"><i class="fa fa-check"></i><b>8.5.2</b> The probability of extreme data</a></li>
<li class="chapter" data-level="8.5.3" data-path="hypothesistesting.html"><a href="hypothesistesting.html#a-common-mistake"><i class="fa fa-check"></i><b>8.5.3</b> A common mistake</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="hypothesistesting.html"><a href="hypothesistesting.html#writeup"><i class="fa fa-check"></i><b>8.6</b> Reporting the results of a hypothesis test</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="hypothesistesting.html"><a href="hypothesistesting.html#the-issue"><i class="fa fa-check"></i><b>8.6.1</b> The issue</a></li>
<li class="chapter" data-level="8.6.2" data-path="hypothesistesting.html"><a href="hypothesistesting.html#two-proposed-solutions"><i class="fa fa-check"></i><b>8.6.2</b> Two proposed solutions</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="hypothesistesting.html"><a href="hypothesistesting.html#effectsize"><i class="fa fa-check"></i><b>8.7</b> Effect size, sample size and power</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="hypothesistesting.html"><a href="hypothesistesting.html#the-power-function"><i class="fa fa-check"></i><b>8.7.1</b> The power function</a></li>
<li class="chapter" data-level="8.7.2" data-path="hypothesistesting.html"><a href="hypothesistesting.html#effect-size"><i class="fa fa-check"></i><b>8.7.2</b> Effect size</a></li>
<li class="chapter" data-level="8.7.3" data-path="hypothesistesting.html"><a href="hypothesistesting.html#increasing-the-power-of-your-study"><i class="fa fa-check"></i><b>8.7.3</b> Increasing the power of your study</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="hypothesistesting.html"><a href="hypothesistesting.html#nhstmess"><i class="fa fa-check"></i><b>8.8</b> Some issues to consider</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="hypothesistesting.html"><a href="hypothesistesting.html#neyman-versus-fisher"><i class="fa fa-check"></i><b>8.8.1</b> Neyman versus Fisher</a></li>
<li class="chapter" data-level="8.8.2" data-path="hypothesistesting.html"><a href="hypothesistesting.html#bayesians-versus-frequentists"><i class="fa fa-check"></i><b>8.8.2</b> Bayesians versus frequentists</a></li>
<li class="chapter" data-level="8.8.3" data-path="hypothesistesting.html"><a href="hypothesistesting.html#traps"><i class="fa fa-check"></i><b>8.8.3</b> Traps</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="hypothesistesting.html"><a href="hypothesistesting.html#summary-4"><i class="fa fa-check"></i><b>8.9</b> Summary</a></li>
</ul></li>
<li class="part"><span><b>STATISTICAL TOOLS</b></span></li>
<li class="chapter" data-level="9" data-path="chisquare.html"><a href="chisquare.html"><i class="fa fa-check"></i><b>9</b> Categorical data analysis</a>
<ul>
<li class="chapter" data-level="9.1" data-path="chisquare.html"><a href="chisquare.html#goftest"><i class="fa fa-check"></i><b>9.1</b> The <span class="math inline">\(\chi^2\)</span> goodness-of-fit test</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="chisquare.html"><a href="chisquare.html#the-null-hypothesis-and-the-alternative-hypothesis"><i class="fa fa-check"></i><b>9.1.1</b> The null hypothesis and the alternative hypothesis</a></li>
<li class="chapter" data-level="9.1.2" data-path="chisquare.html"><a href="chisquare.html#the-goodness-of-fit-test-statistic"><i class="fa fa-check"></i><b>9.1.2</b> The “goodness of fit” test statistic</a></li>
<li class="chapter" data-level="9.1.3" data-path="chisquare.html"><a href="chisquare.html#the-sampling-distribution-of-the-gof-statistic-advanced"><i class="fa fa-check"></i><b>9.1.3</b> The sampling distribution of the GOF statistic (advanced)</a></li>
<li class="chapter" data-level="9.1.4" data-path="chisquare.html"><a href="chisquare.html#degrees-of-freedom"><i class="fa fa-check"></i><b>9.1.4</b> Degrees of freedom</a></li>
<li class="chapter" data-level="9.1.5" data-path="chisquare.html"><a href="chisquare.html#testing-the-null-hypothesis"><i class="fa fa-check"></i><b>9.1.5</b> Testing the null hypothesis</a></li>
<li class="chapter" data-level="9.1.6" data-path="chisquare.html"><a href="chisquare.html#chisqreport"><i class="fa fa-check"></i><b>9.1.6</b> How to report the results of the test</a></li>
<li class="chapter" data-level="9.1.7" data-path="chisquare.html"><a href="chisquare.html#a-comment-on-statistical-notation-advanced"><i class="fa fa-check"></i><b>9.1.7</b> A comment on statistical notation (advanced)</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="chisquare.html"><a href="chisquare.html#chisqindependence"><i class="fa fa-check"></i><b>9.2</b> The <span class="math inline">\(\chi^2\)</span> test of independence (or association)</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="chisquare.html"><a href="chisquare.html#constructing-our-hypothesis-test"><i class="fa fa-check"></i><b>9.2.1</b> Constructing our hypothesis test</a></li>
<li class="chapter" data-level="9.2.2" data-path="chisquare.html"><a href="chisquare.html#AssocTestInCogStat"><i class="fa fa-check"></i><b>9.2.2</b> The test results in CogStat</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="chisquare.html"><a href="chisquare.html#yates"><i class="fa fa-check"></i><b>9.3</b> Yates correction for 1 degree of freedom</a></li>
<li class="chapter" data-level="9.4" data-path="chisquare.html"><a href="chisquare.html#chisqeffectsize"><i class="fa fa-check"></i><b>9.4</b> Effect size (Cramér’s <span class="math inline">\(V\)</span>)</a></li>
<li class="chapter" data-level="9.5" data-path="chisquare.html"><a href="chisquare.html#chisqassumptions"><i class="fa fa-check"></i><b>9.5</b> Assumptions of the test(s)</a></li>
<li class="chapter" data-level="9.6" data-path="chisquare.html"><a href="chisquare.html#fisherexacttest"><i class="fa fa-check"></i><b>9.6</b> The Fisher exact test</a></li>
<li class="chapter" data-level="9.7" data-path="chisquare.html"><a href="chisquare.html#mcnemar"><i class="fa fa-check"></i><b>9.7</b> The McNemar test</a></li>
<li class="chapter" data-level="9.8" data-path="chisquare.html"><a href="chisquare.html#whats-the-difference-between-mcnemar-and-independence"><i class="fa fa-check"></i><b>9.8</b> What’s the difference between McNemar and independence?</a></li>
<li class="chapter" data-level="9.9" data-path="chisquare.html"><a href="chisquare.html#summary-5"><i class="fa fa-check"></i><b>9.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ttest.html"><a href="ttest.html"><i class="fa fa-check"></i><b>10</b> Comparing two means</a>
<ul>
<li class="chapter" data-level="10.1" data-path="ttest.html"><a href="ttest.html#the-one-sample-z-test"><i class="fa fa-check"></i><b>10.1</b> The one-sample <span class="math inline">\(z\)</span>-test</a></li>
<li class="chapter" data-level="10.2" data-path="ttest.html"><a href="ttest.html#onesamplettest"><i class="fa fa-check"></i><b>10.2</b> The one-sample <span class="math inline">\(t\)</span>-test</a></li>
<li class="chapter" data-level="10.3" data-path="ttest.html"><a href="ttest.html#studentttest"><i class="fa fa-check"></i><b>10.3</b> The independent samples <span class="math inline">\(t\)</span>-test (Student test)</a></li>
<li class="chapter" data-level="10.4" data-path="ttest.html"><a href="ttest.html#welchttest"><i class="fa fa-check"></i><b>10.4</b> The independent samples <span class="math inline">\(t\)</span>-test (Welch test)</a></li>
<li class="chapter" data-level="10.5" data-path="ttest.html"><a href="ttest.html#pairedsamplesttest"><i class="fa fa-check"></i><b>10.5</b> The paired-samples <span class="math inline">\(t\)</span>-test</a></li>
<li class="chapter" data-level="10.6" data-path="ttest.html"><a href="ttest.html#cohensd"><i class="fa fa-check"></i><b>10.6</b> Effect size (Cohen’s <span class="math inline">\(d\)</span>)</a></li>
<li class="chapter" data-level="10.7" data-path="ttest.html"><a href="ttest.html#shapiro"><i class="fa fa-check"></i><b>10.7</b> Normality of a sample</a></li>
<li class="chapter" data-level="10.8" data-path="ttest.html"><a href="ttest.html#wilcox"><i class="fa fa-check"></i><b>10.8</b> Testing non-normal data with Wilcoxon tests</a>
<ul>
<li class="chapter" data-level="10.8.1" data-path="ttest.html"><a href="ttest.html#two-sample-wilcoxon-test-mann-whitney-test"><i class="fa fa-check"></i><b>10.8.1</b> Two-sample Wilcoxon test (Mann-Whitney test)</a></li>
<li class="chapter" data-level="10.8.2" data-path="ttest.html"><a href="ttest.html#one-sample-and-paired-samples-wilcoxon-tests"><i class="fa fa-check"></i><b>10.8.2</b> One-sample and paired samples Wilcoxon tests</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="ttest.html"><a href="ttest.html#summary-6"><i class="fa fa-check"></i><b>10.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="anova.html"><a href="anova.html"><i class="fa fa-check"></i><b>11</b> Comparing several means (one-way ANOVA)</a>
<ul>
<li class="chapter" data-level="11.1" data-path="anova.html"><a href="anova.html#the-data"><i class="fa fa-check"></i><b>11.1</b> The data</a></li>
<li class="chapter" data-level="11.2" data-path="anova.html"><a href="anova.html#anovaintro"><i class="fa fa-check"></i><b>11.2</b> How ANOVA works</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="anova.html"><a href="anova.html#from-variance"><i class="fa fa-check"></i><b>11.2.1</b> From variance…</a></li>
<li class="chapter" data-level="11.2.2" data-path="anova.html"><a href="anova.html#to-total-sum-of-squares"><i class="fa fa-check"></i><b>11.2.2</b> … to total sum of squares</a></li>
<li class="chapter" data-level="11.2.3" data-path="anova.html"><a href="anova.html#from-sums-of-squares-to-the-f-test"><i class="fa fa-check"></i><b>11.2.3</b> From sums of squares to the <span class="math inline">\(F\)</span>-test</a></li>
<li class="chapter" data-level="11.2.4" data-path="anova.html"><a href="anova.html#anovamodel"><i class="fa fa-check"></i><b>11.2.4</b> Further reading: the meaning of <span class="math inline">\(F\)</span> (advanced)</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="anova.html"><a href="anova.html#introduceaov"><i class="fa fa-check"></i><b>11.3</b> Interpreting our results in CogStat</a></li>
<li class="chapter" data-level="11.4" data-path="anova.html"><a href="anova.html#anovaeffect"><i class="fa fa-check"></i><b>11.4</b> Effect size</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="anova.html"><a href="anova.html#eta-squared"><i class="fa fa-check"></i><b>11.4.1</b> Eta-squared</a></li>
<li class="chapter" data-level="11.4.2" data-path="anova.html"><a href="anova.html#omega-squared"><i class="fa fa-check"></i><b>11.4.2</b> Omega-squared</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="anova.html"><a href="anova.html#posthoc"><i class="fa fa-check"></i><b>11.5</b> Post hoc tests</a></li>
<li class="chapter" data-level="11.6" data-path="anova.html"><a href="anova.html#levene"><i class="fa fa-check"></i><b>11.6</b> Checking the homogeneity of variance assumption</a></li>
<li class="chapter" data-level="11.7" data-path="anova.html"><a href="anova.html#kruskalwallis"><i class="fa fa-check"></i><b>11.7</b> Testing for non-normal data with Kruskal-Wallis test</a></li>
<li class="chapter" data-level="11.8" data-path="anova.html"><a href="anova.html#anovaandt"><i class="fa fa-check"></i><b>11.8</b> On the relationship between ANOVA and the Student <span class="math inline">\(t\)</span>-test</a></li>
<li class="chapter" data-level="11.9" data-path="anova.html"><a href="anova.html#summary-7"><i class="fa fa-check"></i><b>11.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>12</b> Linear regression</a></li>
<li class="chapter" data-level="13" data-path="anova2.html"><a href="anova2.html"><i class="fa fa-check"></i><b>13</b> Factorial ANOVA</a></li>
<li class="part"><span><b>BAYESIAN STATISTICS</b></span></li>
<li class="chapter" data-level="14" data-path="bayes.html"><a href="bayes.html"><i class="fa fa-check"></i><b>14</b> Introduction to Bayesian statistics</a></li>
<li class="chapter" data-level="15" data-path="bayesianhypothesistests.html"><a href="bayesianhypothesistests.html"><i class="fa fa-check"></i><b>15</b> Bayesian hypothesis tests</a></li>
<li class="chapter" data-level="16" data-path="whybayes.html"><a href="whybayes.html"><i class="fa fa-check"></i><b>16</b> Why be a Bayesian?</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Learning Statistics with CogStat</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chisquare" class="section level1 hasAnchor" number="9">
<h1><span class="header-section-number">Chapter 9</span> Categorical data analysis<a href="chisquare.html#chisquare" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Now that we’ve got the basic theory behind hypothesis testing, it’s time to start looking at specific tests commonly used in psychology that CogStat will automatically run for you during analysis. We’ll start with “<span class="math inline">\(\chi^2\)</span> tests” (pronounced as ‘chi square’) in this chapter and “<span class="math inline">\(t\)</span>-tests” (Chapter <a href="ttest.html#ttest">10</a>) in the next one. Both of these tools are very frequently used in scientific practice for comparing groups. While they’re not as powerful as “analysis of variance” (Chapter <a href="anova.html#anova">11</a>) and “regression” (Chapter <a href="regression.html#regression">12</a>), they’re much easier to understand.</p>
<p>The term “categorical data” is the term preferred by data analysis people, but it’s just another name for “nominal scale data”. To refresh your memory on data types, please revisit our introductory chapter on scales of measurement and types of variables (see Chapter <a href="researchdesign.html#scales">3.2</a>).</p>
<p>In any case, <strong>categorical data analysis</strong> refers to a collection of tools that you can use when your data are nominal scale. We can use many tools for categorical data analysis, but this chapter only covers a few of the more common ones.</p>
<div id="goftest" class="section level2 hasAnchor" number="9.1">
<h2><span class="header-section-number">9.1</span> The <span class="math inline">\(\chi^2\)</span> goodness-of-fit test<a href="chisquare.html#goftest" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The <span class="math inline">\(\chi^2\)</span> goodness-of-fit test is one of the oldest hypothesis tests around: it was invented by Karl Pearson around the turn of the century <span class="citation">(Pearson, 1900)</span>, with some corrections made later by Sir Ronald Fisher <span class="citation">(Fisher, 1922a)</span>. Let’s start with some psychology to introduce the statistical problem it addresses.</p>
<p>Over the years, there have been a lot of studies showing that humans have a lot of difficulties in simulating randomness. Try as we might to “act” random, we <em>think</em> in terms of patterns and structure, and so when asked to “do something at random”, what people do is anything but random. Consequently, the study of human randomness (or non-randomness, as the case may be) opens up a lot of deep psychological questions about how we think about the world. With this in mind, let’s consider a very simple study. Suppose we asked people to imagine a shuffled deck of cards and mentally pick one card from this imaginary deck “at random”. After they’ve chosen one card, we ask them to select a second one mentally. For both choices, we’re going to look at the suit (hearts, clubs, spades or diamonds) that people chose. After asking, say, <span class="math inline">\(N=200\)</span> people to do this, we’d like to look at the data and figure out whether or not the cards that people pretended to select were random. The data are contained in the <a href="resources/data/cards.csv"><code>cards.csv</code></a> file, which we will load into CogStat. For the moment, let’s just focus on the first choice that people made (<code>choice_1</code>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:cogstatloadcards"></span>
<img src="resources/image/cogstatloadcards.png" alt="Loading the cards.csv data and running `Explore variable` command on `choice_1`" width="100%" /><img src="resources/image/cogstatcardsdescrhisto.png" alt="Loading the cards.csv data and running `Explore variable` command on `choice_1`" width="100%" />
<p class="caption">
Figure 9.1: Loading the cards.csv data and running <code>Explore variable</code> command on <code>choice_1</code>
</p>
</div>
<p><strong>Important note:</strong>
CogStat currently doesn’t support single-variable hypothesis testing for nominal scale data. However, this chapter will still be useful for you to understand the tools used in hypothesis testing, and you can use them as described here in other software packages.</p>
<p>We can see that the data are nominal scale, so we’ll use the <span class="math inline">\(\chi^2\)</span> goodness-of-fit test to analyze them. We’ll also use the “Fisher’s exact test” option, which is a more powerful version of the <span class="math inline">\(\chi^2\)</span> test that is appropriate when the sample size is small (less than 40). We’ll also use the “Bonferroni correction” option, which is a way of correcting for multiple comparisons. We’ll talk more about this in Chapter <a href="#multcomp"><strong>??</strong></a>. For now, let’s just run the analysis.</p>
<p>That little frequency table in Figure <a href="chisquare.html#fig:cogstatloadcards">9.1</a> is quite helpful. Looking at it, there’s a bit of a hint that people <em>might</em> be more likely to select hearts than clubs, but it’s not completely obvious just from looking at it whether that’s really true, or if this is just due to chance. So we’ll probably have to do some kind of statistical analysis to find out, which is what we’re going to talk about in the next section.</p>
<p>A quick side-note here: the mathematical notation of observations (i.e. an element in the data set) is <span class="math inline">\(0_i\)</span>, where <span class="math inline">\(O\)</span> stands for observation (but could very well be the traditional <span class="math inline">\(X\)</span> or <span class="math inline">\(Y\)</span> etc.) and <span class="math inline">\(i\)</span> is the index of the observation. So <span class="math inline">\(0_1\)</span> is the first observation, <span class="math inline">\(0_2\)</span> is the second observation, and so on.</p>
<div id="the-null-hypothesis-and-the-alternative-hypothesis" class="section level3 hasAnchor" number="9.1.1">
<h3><span class="header-section-number">9.1.1</span> The null hypothesis and the alternative hypothesis<a href="chisquare.html#the-null-hypothesis-and-the-alternative-hypothesis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Our research hypothesis is that “people don’t choose cards randomly”. What we’re going to want to do now is translate this into some statistical hypotheses, and construct a statistical test of those hypotheses. The test is <strong>Pearson’s <span class="math inline">\(\chi^2\)</span> goodness of fit test</strong>.</p>
<p>As is so often the case, we have to begin by carefully constructing our null hypothesis. In this case, it’s pretty easy. First, let’s state the null hypothesis in words.</p>
<blockquote>
<p><strong>Null hypothesis</strong> (<span class="math inline">\(H_0\)</span>): All four suits are chosen with equal probability.</p>
</blockquote>
<p>Now, because this is statistics, we have to be able to say the same thing mathematically. Let’s use the notation <span class="math inline">\(P_j\)</span> to refer to the true <em>probability</em> that the <span class="math inline">\(j\)</span>-th suit is chosen. If the null hypothesis is true, then each of the four suits has a 25% chance of being selected: in other words, our null hypothesis claims that <span class="math inline">\(P_1 = 0.25\)</span>, <span class="math inline">\(P_2 = 0.25\)</span>, <span class="math inline">\(P_3 = 0.25\)</span> and finally that <span class="math inline">\(P_4 = 0.25\)</span>. We can use <span class="math inline">\(P\)</span> to refer to the probabilities corresponding to our null hypothesis. So if we let the vector <span class="math inline">\(P = (P_1, P_2, P_3, P_4)\)</span> refer to the collection of probabilities that describe our null hypothesis, then we have</p>
<p><span class="math display">\[
H_0: {P} = (0.25, 0.25, 0.25, 0.25)
\]</span></p>
<p>If the experimental task were for people to imagine they were drawing from a deck that had twice as many clubs as any other suit, then the null hypothesis would correspond to something like <span class="math inline">\(P = (0.4, 0.2, 0.2, 0.2)\)</span>. As long as the probabilities are all positive numbers, and they all sum to 1, then it’s a perfectly legitimate choice for the null hypothesis. However, the most common use of the goodness of fit test is to test a null hypothesis that all categories are equally likely, so we’ll stick to that for our example.</p>
<p>What about our alternative hypothesis, <span class="math inline">\(H_1\)</span>? We’re interested in demonstrating that the probabilities involved aren’t all identical (that is, people’s choices weren’t entirely random). As a consequence, the “human-friendly” versions of our hypotheses look like this:</p>
<blockquote>
<p><strong>Null hypothesis</strong> (<span class="math inline">\(H_0\)</span>): All four suits are chosen with equal probability.<br />
<strong>Alternative hypothesis</strong> (<span class="math inline">\(H_1\)</span>): At least one of the suit-choice probabilities <em>isn’t</em> 0.25.</p>
</blockquote>
<p>and the “mathematician friendly” version is</p>
<table>
<thead>
<tr>
<th style="text-align:center;">
<span class="math inline">\(H_0\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(H_1\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
<span class="math inline">\(P = (0.25, 0.25, 0.25, 0.25)\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(P \neq (0.25,0.25,0.25,0.25)\)</span>
</td>
</tr>
</tbody>
</table>
</div>
<div id="the-goodness-of-fit-test-statistic" class="section level3 hasAnchor" number="9.1.2">
<h3><span class="header-section-number">9.1.2</span> The “goodness of fit” test statistic<a href="chisquare.html#the-goodness-of-fit-test-statistic" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>What we now want to do is construct a test of the null hypothesis. As always, if we want to test <span class="math inline">\(H_0\)</span> against <span class="math inline">\(H_1\)</span>, we will need a test statistic. The basic trick that a goodness of fit test uses is to construct a test statistic that measures how “close” the data are to the null hypothesis. If the data don’t resemble what you’d “expect” to see if the null hypothesis were true, then it probably isn’t true.</p>
<p>So, what would we expect to see if the null hypothesis were true? Or, to use the correct terminology, what are the <strong>expected frequencies</strong>?</p>
<p>There are <span class="math inline">\(N=200\)</span> observations, and (if the null is true) the probability of any one of them choosing a heart is <span class="math inline">\(P_3 = 0.25\)</span>, so we’re expecting <span class="math inline">\(200 \times 0.25 = 50\)</span> hearts, right? Or, more specifically, if we let <span class="math inline">\(E_i\)</span> refer to “the number of category <span class="math inline">\(i\)</span> responses that we’re expecting if the null is true”, then
<span class="math display">\[
E_i = N \times P_i
\]</span></p>
<p>Clearly, what we want to do is compare the <em>expected</em> number of observations in each category (<span class="math inline">\(E_i\)</span>) with the <em>observed</em> number of observations in that category (<span class="math inline">\(O_i\)</span>). And on the basis of this comparison, we ought to be able to come up with a good test statistic. To start with, let’s calculate the difference between what the null hypothesis expected us to find and what we actually did find. That is, we calculate the “observed minus expected” difference score, <span class="math inline">\(O_i - E_i\)</span>. This is illustrated in the following table.</p>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
<span class="math inline">\(\clubsuit\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(\diamondsuit\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(\heartsuit\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(\spadesuit\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Expected frequency
</td>
<td style="text-align:left;">
<span class="math inline">\(E_i\)</span>
</td>
<td style="text-align:right;">
50
</td>
<td style="text-align:right;">
50
</td>
<td style="text-align:right;">
50
</td>
<td style="text-align:right;">
50
</td>
</tr>
<tr>
<td style="text-align:left;">
Observed frequency
</td>
<td style="text-align:left;">
<span class="math inline">\(O_i\)</span>
</td>
<td style="text-align:right;">
35
</td>
<td style="text-align:right;">
51
</td>
<td style="text-align:right;">
64
</td>
<td style="text-align:right;">
50
</td>
</tr>
<tr>
<td style="text-align:left;">
Difference score
</td>
<td style="text-align:left;">
<span class="math inline">\(O_i - E_i\)</span>
</td>
<td style="text-align:right;">
-15
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
14
</td>
<td style="text-align:right;">
0
</td>
</tr>
</tbody>
</table>
<p>It’s clear that people chose more hearts and fewer clubs than the null hypothesis predicted. However, a moment’s thought suggests that these raw differences aren’t quite what we’re looking for. Intuitively, it feels like it’s just as bad when the null hypothesis predicts too few observations (which is what happened with hearts) as it is when it predicts too many (which is what happened with clubs). So it’s a bit weird that we have a negative number for clubs and a positive number for hearts.</p>
<p>One easy way to fix this is to square everything so that we now calculate the squared differences, <span class="math inline">\((E_i - O_i)^2\)</span>.</p>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
<span class="math inline">\(\clubsuit\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(\diamondsuit\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(\heartsuit\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(\spadesuit\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Expected frequency
</td>
<td style="text-align:left;">
<span class="math inline">\(E_i\)</span>
</td>
<td style="text-align:right;">
50
</td>
<td style="text-align:right;">
50
</td>
<td style="text-align:right;">
50
</td>
<td style="text-align:right;">
50
</td>
</tr>
<tr>
<td style="text-align:left;">
Observed frequency
</td>
<td style="text-align:left;">
<span class="math inline">\(O_i\)</span>
</td>
<td style="text-align:right;">
35
</td>
<td style="text-align:right;">
51
</td>
<td style="text-align:right;">
64
</td>
<td style="text-align:right;">
50
</td>
</tr>
<tr>
<td style="text-align:left;">
Difference score
</td>
<td style="text-align:left;">
<span class="math inline">\(O_i - E_i\)</span>
</td>
<td style="text-align:right;">
-15
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
14
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
Squared differences
</td>
<td style="text-align:left;">
<span class="math inline">\(\left(O_i - E_i\right)^2\)</span>
</td>
<td style="text-align:right;">
225
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
196
</td>
<td style="text-align:right;">
0
</td>
</tr>
</tbody>
</table>
<p>Now we’re making progress. Now, we’ve got a collection of numbers that are big whenever the null hypothesis makes a lousy prediction (clubs and hearts) but small whenever it makes a good one (diamonds and spades).</p>
<p>Next, let’s also divide all these numbers by the expected frequency <span class="math inline">\(E_i\)</span>, so we’re calculating <span class="math inline">\(\frac{(E_i-O_i)^2}{E_i}\)</span>. Since <span class="math inline">\(E_i = 50\)</span> for all categories in our example, it’s not a very interesting calculation, but let’s do it anyway.</p>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
</th>
<th style="text-align:center;">
<span class="math inline">\(\clubsuit\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(\diamondsuit\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(\heartsuit\)</span>
</th>
<th style="text-align:left;">
<span class="math inline">\(\spadesuit\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Expected frequency
</td>
<td style="text-align:left;">
<span class="math inline">\(E_i\)</span>
</td>
<td style="text-align:center;">
50
</td>
<td style="text-align:center;">
50
</td>
<td style="text-align:center;">
50
</td>
<td style="text-align:left;">
50
</td>
</tr>
<tr>
<td style="text-align:left;">
Observed frequency
</td>
<td style="text-align:left;">
<span class="math inline">\(O_i\)</span>
</td>
<td style="text-align:center;">
35
</td>
<td style="text-align:center;">
51
</td>
<td style="text-align:center;">
64
</td>
<td style="text-align:left;">
50
</td>
</tr>
<tr>
<td style="text-align:left;">
Difference score
</td>
<td style="text-align:left;">
<span class="math inline">\(O_i - E_i\)</span>
</td>
<td style="text-align:center;">
-15
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
14
</td>
<td style="text-align:left;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
Squared differences
</td>
<td style="text-align:left;">
<span class="math inline">\(\left(O_i - E_i\right)^2\)</span>
</td>
<td style="text-align:center;">
225
</td>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
196
</td>
<td style="text-align:left;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
Squared differences divided by expected frequency
</td>
<td style="text-align:left;">
<span class="math inline">\(\frac{\left(O_i - E_i\right)^2}{E_i}\)</span>
</td>
<td style="text-align:center;">
4.5
</td>
<td style="text-align:center;">
0.02
</td>
<td style="text-align:center;">
3.92
</td>
<td style="text-align:left;">
0
</td>
</tr>
</tbody>
</table>
<p>In effect, what we’ve got here are four different “error” scores, each one telling us how big a “mistake” the null hypothesis made when we tried to use it to predict our observed frequencies. So, in order to convert this into a useful test statistic, one thing we could do is just add these numbers up. We get
<span class="math display">\[
X^2 = 8.42
\]</span></p>
<p>The result is called the <strong>goodness of fit</strong> statistic, conventionally referred to either as <span class="math inline">\(X^2\)</span> or GOF. If we let <span class="math inline">\(k\)</span> refer to the total number of categories (i.e. <span class="math inline">\(k=4\)</span> for our cards data), then the <span class="math inline">\(X^2\)</span> statistic is given by the following formula:
<span class="math display">\[
X^2 = \sum_{i=1}^k \frac{(O_i - E_i)^2}{E_i}
\]</span></p>
<p>Intuitively, it’s clear that if <span class="math inline">\(X^2\)</span> is small, then the observed data <span class="math inline">\(O_i\)</span> are very close to what the null hypothesis predicted <span class="math inline">\(E_i\)</span>, so we’re going to need a large <span class="math inline">\(X^2\)</span> statistic in order to reject the null. As we’ve seen from our calculations, we’ve got a value of <span class="math inline">\(X^2 = 8.44\)</span> in our cards data set. So now the question becomes, is this a big enough value to reject the null?</p>
</div>
<div id="the-sampling-distribution-of-the-gof-statistic-advanced" class="section level3 hasAnchor" number="9.1.3">
<h3><span class="header-section-number">9.1.3</span> The sampling distribution of the GOF statistic (advanced)<a href="chisquare.html#the-sampling-distribution-of-the-gof-statistic-advanced" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To determine whether or not a particular value of <span class="math inline">\(X^2\)</span> is large enough to justify rejecting the null hypothesis, we will need to figure out what the sampling distribution for <span class="math inline">\(X^2\)</span> would be if the null hypothesis were true. If you want to cut to the chase and are willing to take it on faith that the sampling distribution is a <strong>chi-squared (<span class="math inline">\(\chi^2\)</span>) distribution</strong> with <span class="math inline">\(k-1\)</span> degrees of freedom, you can skip the rest of this section. However, if you want to understand <em>why</em> the goodness of fit test works the way it does, read on.</p>
<p>Let’s suppose that the null hypothesis is true. If so, then the true probability that an observation falls in the <span class="math inline">\(i\)</span>-th category is <span class="math inline">\(P_i\)</span>. After all, that’s the definition of our null hypothesis. If you think about it, this is kind of like saying that “nature” decides whether or not the observation ends up in category <span class="math inline">\(i\)</span> by flipping a weighted coin (i.e. one where the probability of getting a head is <span class="math inline">\(P_j\)</span>). And therefore, we can think of our observed frequency <span class="math inline">\(O_i\)</span> by imagining that nature flipped <span class="math inline">\(N\)</span> of these coins (one for each observation in the data set). And exactly <span class="math inline">\(O_i\)</span> of them came up heads. Obviously, this is a pretty weird way to think about the experiment. But it reminds you that we’ve seen this scenario before. It’s exactly the same set-up that gave rise to the binomial distribution in Chapter <a href="probability.html#binomial">6.4.1</a>. In other words, if the null hypothesis is true, then it follows that our observed frequencies were generated by sampling from a binomial distribution:
<span class="math display">\[
O_i \sim \mbox{Binomial}(P_i, N)
\]</span>
Now, if you remember from our discussion of the central limit theorem (Section <a href="estimation.html#clt">7.3.3</a>), the binomial distribution starts to look pretty much identical to the normal distribution, especially when <span class="math inline">\(N\)</span> is large and when <span class="math inline">\(P_i\)</span> isn’t <em>too</em> close to 0 or 1.</p>
<p>In other words, as long as <span class="math inline">\(N \times P_i\)</span> is large enough – or, to put it another way, when the expected frequency <span class="math inline">\(E_i\)</span> is large enough – the theoretical distribution of <span class="math inline">\(O_i\)</span> is approximately normal. Better yet, if <span class="math inline">\(O_i\)</span> is normally distributed, then so is <span class="math inline">\((O_i - E_i)/\sqrt{E_i}\)</span> … since <span class="math inline">\(E_i\)</span> is a fixed value, subtracting off <span class="math inline">\(E_i\)</span> and dividing by <span class="math inline">\(\sqrt{E_i}\)</span> changes the mean and standard deviation of the normal distribution.</p>
<p>Okay, so now let’s have a look at what our goodness of fit statistic actually <em>is</em>. What we’re doing is taking a bunch of things that are normally distributed, squaring them, and adding them up. As we discussed in Chapter <a href="probability.html#otherdists">6.4.4</a>, when you take a bunch of things that have a standard normal distribution (i.e. mean 0 and standard deviation 1), square them, then add them up, then the resulting quantity has a chi-square distribution. So now we know that the null hypothesis predicts that the sampling distribution of the goodness of fit statistic is a chi-square distribution.</p>
<p>There’s one last detail to talk about, namely the degrees of freedom. If you remember back to Chapter <a href="probability.html#otherdists">6.4.4</a>, if the number of things you’re adding up is <span class="math inline">\(k\)</span>, then the degrees of freedom for the resulting chi-square distribution is <span class="math inline">\(k\)</span>. Yet, at the start of this section, we said that the actual degrees of freedom for the chi-square goodness of fit test is <span class="math inline">\(k-1\)</span>. What’s up with that? The answer here is that what we’re supposed to be looking at is the number of genuinely <em>independent</em> things that are getting added together. And, even though there are <span class="math inline">\(k\)</span> things that we’re adding, only <span class="math inline">\(k-1\)</span> of them are truly independent; and so the degrees of freedom are actually only <span class="math inline">\(k-1\)</span>.</p>
</div>
<div id="degrees-of-freedom" class="section level3 hasAnchor" number="9.1.4">
<h3><span class="header-section-number">9.1.4</span> Degrees of freedom<a href="chisquare.html#degrees-of-freedom" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:manychi"></span>
<img src="lsc_files/figure-html/manychi-1.svg" alt="Chi-square distributions with different values for the &quot;degrees of freedom&quot;." width="672" />
<p class="caption">
Figure 9.2: Chi-square distributions with different values for the “degrees of freedom”.
</p>
</div>
<p>When discussing the chi-square distribution in Chapter <a href="probability.html#otherdists">6.4.4</a>, we didn’t elaborate on what “<strong>degrees of freedom</strong>” actually <em>mean</em>. Looking at Figure <a href="chisquare.html#fig:manychi">9.2</a>, you can see that if we change the degrees of freedom, then the chi-square distribution changes shape substantially. But what exactly <em>is</em> it? It’s the number of “normally distributed variables” that we are squaring and adding together. But, for most people, that’s kind of abstract and not entirely helpful. What we really need to do is try to understand degrees of freedom in terms of our data. So here goes.</p>
<p>The basic idea behind degrees of freedom is quite simple: you calculate it by counting up the number of distinct “quantities” that are used to describe your data; and then subtracting off all of the “constraints” that those data must satisfy.<a href="#fn35" class="footnote-ref" id="fnref35"><sup>35</sup></a> This is a bit vague, so let’s use our <code>cards.csv</code> data as a concrete example.</p>
<p>We describe our data using four numbers, <span class="math inline">\(O_1\)</span>, <span class="math inline">\(O_2\)</span>, <span class="math inline">\(O_3\)</span> and <span class="math inline">\(O_4\)</span> corresponding to the observed frequencies of the four different categories (hearts, clubs, diamonds, spades). These four numbers are the <em>random outcomes</em> of our experiment. But, the experiment has a fixed constraint built into it: the sample size <span class="math inline">\(N\)</span>.<a href="#fn36" class="footnote-ref" id="fnref36"><sup>36</sup></a> That is, if we know how many people chose hearts, how many chose diamonds and how many chose clubs, then we’d be able to figure out exactly how many chose spades. In other words, although our data are described using four numbers, they only actually correspond to <span class="math inline">\(4-1 = 3\)</span> degrees of freedom. A slightly different way of thinking about it is to notice that there are four <em>probabilities</em> that we’re interested in (again, corresponding to the four different categories), but these probabilities must sum to one, which imposes a constraint. Therefore, the degrees of freedom is <span class="math inline">\(4-1 = 3\)</span>. Regardless of whether you want to think about it in terms of the observed frequencies or in terms of the probabilities, the answer is the same. In general, when running the chi-square goodness of fit test for an experiment involving <span class="math inline">\(k\)</span> groups, then the degrees of freedom will be <span class="math inline">\(k-1\)</span>.</p>
</div>
<div id="testing-the-null-hypothesis" class="section level3 hasAnchor" number="9.1.5">
<h3><span class="header-section-number">9.1.5</span> Testing the null hypothesis<a href="chisquare.html#testing-the-null-hypothesis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:goftest"></span>
<img src="lsc_files/figure-html/goftest-1.svg" alt="Illustration of how the hypothesis testing works for the chi-square goodness of fit test." width="672" />
<p class="caption">
Figure 9.3: Illustration of how the hypothesis testing works for the chi-square goodness of fit test.
</p>
</div>
<p>The final step in constructing our hypothesis test is to figure out what the rejection region is. That is, what values of <span class="math inline">\(X^2\)</span> would lead us to reject the null hypothesis? As we saw earlier, large values of <span class="math inline">\(X^2\)</span> imply that the null hypothesis has done a poor job of predicting the data from our experiment, whereas small values of <span class="math inline">\(X^2\)</span> imply that it’s actually done pretty well. Therefore, a pretty sensible strategy would be to say there is some critical value, such that if <span class="math inline">\(X^2\)</span> is bigger than the critical value, we reject the null; but if <span class="math inline">\(X^2\)</span> is smaller than this value, we retain the null.</p>
<p>In other words, to use the language we introduced in Chapter <a href="hypothesistesting.html#hypothesistesting">8</a>, the chi-squared goodness of fit test is always a <strong>one-sided test</strong>. If we want our test to have a significance level of <span class="math inline">\(\alpha = .05\)</span> (that is, we are willing to tolerate a Type I error rate of 5%), then we have to choose our critical value so that there is only a 5% chance that <span class="math inline">\(X^2\)</span> could get to be that big if the null hypothesis is true. Meaning that we want the 95th percentile of the sampling distribution. This is illustrated in Figure <a href="chisquare.html#fig:goftest">9.3</a>. So if our <span class="math inline">\(X^2\)</span> statistic is bigger than 7.814728, then we can reject the null hypothesis. Since we calculated that before (i.e. <span class="math inline">\(X^2 = 8.44\)</span>), we can reject the null.</p>
<p>The corresponding <span class="math inline">\(p\)</span>-value is 0.03774185. This is the probability of getting a value of <span class="math inline">\(X^2\)</span> as big as 8.44, or bigger, if the null hypothesis is true. Since this is less than our significance level of <span class="math inline">\(\alpha = .05\)</span>, we can reject the null hypothesis.</p>
<p>And that’s it, basically. You now know <strong>Pearson’s <span class="math inline">\(\chi^2\)</span> test for the goodness of fit</strong>.</p>
</div>
<div id="chisqreport" class="section level3 hasAnchor" number="9.1.6">
<h3><span class="header-section-number">9.1.6</span> How to report the results of the test<a href="chisquare.html#chisqreport" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If we wanted to write this result up for a paper or something, the conventional way to report this would be to write something like this:</p>
<blockquote>
<p>Of the 200 participants in the experiment, 64 selected hearts for their first choice, 51 selected diamonds, 50 selected spades, and 35 selected clubs. A chi-square goodness of fit test was conducted to test whether the choice probabilities were identical for all four suits. The results were significant (<span class="math inline">\(\chi^2(3) = 8.44, p&lt;.05\)</span>), suggesting that people did not select suits purely at random.</p>
</blockquote>
<p>This is pretty straightforward, and hopefully it seems pretty unremarkable. There are a few things that you should note about this description:</p>
<ul>
<li><em>The statistical test is preceded by descriptive statistics</em>. That is, we told the reader something about what the data looked like before going on to do the test. In general, this is good practice: remember that your reader doesn’t know your data anywhere near as well as you do. So unless you describe it to them adequately, the statistical tests won’t make sense to them.</li>
<li><em>The description tells you what the null hypothesis being tested is</em>. Writers don’t always do this, but it’s often a good idea in those situations where some ambiguity exists; or when you can’t rely on your readership being intimately familiar with the statistical tools you’re using. Quite often, the reader might not know (or remember) all the details of the test that your using, so it’s a kind of politeness to “remind” them! As far as the goodness of fit test goes, you can usually rely on a scientific audience knowing how it works (since it’s covered in most intro stats classes). However, it’s still a good idea to explicitly state the null hypothesis (briefly!) because the null hypothesis can differ depending on your test. For instance, in the cards example our null hypothesis was that all the four suit probabilities were identical (i.e. <span class="math inline">\(P_1 = P_2 = P_3 = P_4 = 0.25\)</span>), but there’s nothing special about that hypothesis. We could just as easily have tested the null hypothesis that <span class="math inline">\(P_1 = 0.7\)</span> and <span class="math inline">\(P_2 = P_3 = P_4 = 0.1\)</span> using a goodness of fit test. So it’s helpful to the reader to explain your null hypothesis to them. Also, we described the null hypothesis in words, not in maths. That’s perfectly acceptable. You can describe it in maths if you like, but since most readers find words easier to read than symbols, most writers tend to describe the null using words if they can.</li>
<li><em>A “stat block” is included</em>. When reporting the results of the test itself, We didn’t just say that the result was significant; we included a “stat block” (i.e. the dense mathematical-looking part in the parentheses), which reports all the “raw” statistical data. For the chi-square goodness of fit test, the information that gets reported is the test statistic (that the goodness of fit statistic was 8.44), the information about the distribution used in the test (<span class="math inline">\(\chi^2\)</span> with 3 degrees of freedom, which is usually shortened to <span class="math inline">\(\chi^2(3)\)</span>), and then the information about whether the result was significant (in this case <span class="math inline">\(p&lt;.05\)</span>). The particular information that needs to go into the stat block is different for every test, and so each time we introduce a new test, we’ll show you what the stat block should look like. The general principle is that you should always provide enough information so that the reader can check the test results themselves if they really want to.</li>
<li><em>The results are interpreted</em>. In addition to indicating that the result was significant, we provided an interpretation of the result (i.e. that people didn’t choose randomly). This is also a kindness to the reader because it tells them what they should believe about your data. If you don’t include something like this, it’s tough for your reader to understand what’s going on.<a href="#fn37" class="footnote-ref" id="fnref37"><sup>37</sup></a></li>
</ul>
<p>As with everything else, your overriding concern should be that you <em>explain</em> things to your reader.</p>
</div>
<div id="a-comment-on-statistical-notation-advanced" class="section level3 hasAnchor" number="9.1.7">
<h3><span class="header-section-number">9.1.7</span> A comment on statistical notation (advanced)<a href="chisquare.html#a-comment-on-statistical-notation-advanced" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If you’ve been reading very closely, there is one thing about how we wrote up the chi-square test in the last section that might be bugging you a little bit. There’s something that feels a bit wrong with writing “<span class="math inline">\(\chi^2(3) = 8.44\)</span>”, you might be thinking. After all, it’s the goodness of fit statistic that is equal to 8.44, so shouldn’t I have written <span class="math inline">\(X^2 = 8.44\)</span> or maybe GOF<span class="math inline">\(=8.44\)</span>? This seems to be conflating the <em>sampling distribution</em> (i.e. <span class="math inline">\(\chi^2\)</span> with <span class="math inline">\(df = 3\)</span>) with the <em>test statistic</em> (i.e. <span class="math inline">\(X^2\)</span>). You figured it was a typo since <span class="math inline">\(\chi\)</span> and <span class="math inline">\(X\)</span> look pretty similar. Oddly, it’s not. Writing <span class="math inline">\(\chi^2(3) = 8.44\)</span> is essentially a highly condensed way of writing “the sampling distribution of the test statistic is <span class="math inline">\(\chi^2(3)\)</span>, and the value of the test statistic is 8.44”.</p>
<p>In one sense, this is kind of stupid. There are <em>lots</em> of different test statistics out there that have a chi-square sampling distribution: the <span class="math inline">\(X^2\)</span> statistic that we’ve used for our goodness of fit test is only one of many (albeit one of the most commonly encountered ones). In a sensible, perfectly organised world, we’d <em>always</em> have a separate name for the test statistic and the sampling distribution: that way, the stat block itself would tell you precisely what it was that the researcher had calculated. Sometimes this happens.</p>
<p>For instance, the test statistic used in the Pearson goodness of fit test is written <span class="math inline">\(X^2\)</span>; but there’s a closely related test known as the <span class="math inline">\(G\)</span>-test<a href="#fn38" class="footnote-ref" id="fnref38"><sup>38</sup></a> , in which the test statistic is written as <span class="math inline">\(G\)</span>. As it happens, the Pearson goodness of fit test and the <span class="math inline">\(G\)</span>-test both test the same null hypothesis; and the sampling distribution is exactly the same (i.e. chi-square with <span class="math inline">\(k-1\)</span> degrees of freedom). If we’d done a <span class="math inline">\(G\)</span>-test for the cards data rather than a goodness of fit test, then we’d have ended up with a test statistic of <span class="math inline">\(G = 8.65\)</span>, which is slightly different from the <span class="math inline">\(X^2 = 8.44\)</span>; and produces a slightly smaller <span class="math inline">\(p\)</span>-value of <span class="math inline">\(p = .034\)</span>. Suppose that the convention was to report the test statistic, then the sampling distribution, and then the <span class="math inline">\(p\)</span>-value. If that were true, then these two situations would produce different stat blocks: the original result would be written <span class="math inline">\(X^2 = 8.44, \chi^2(3), p = .038\)</span>, whereas the new version using the <span class="math inline">\(G\)</span>-test would be written as <span class="math inline">\(G = 8.65, \chi^2(3), p = .034\)</span>. However, using the condensed reporting standard, the original result is written <span class="math inline">\(\chi^2(3) = 8.44, p = .038\)</span>, and the new one is written <span class="math inline">\(\chi^2(3) = 8.65, p = .034\)</span>, and so it’s actually unclear which test was actually run.</p>
<p>So why don’t we live in a world where the stat block’s contents uniquely specify what tests were run? Any test statistic that follows a <span class="math inline">\(\chi^2\)</span> distribution is commonly called a “chi-square statistic”; anything that follows a <span class="math inline">\(t\)</span>-distribution is called a “<span class="math inline">\(t\)</span>-statistic” and so on. But, as the <span class="math inline">\(X^2\)</span> versus <span class="math inline">\(G\)</span> example illustrates, two different things with the same sampling distribution are still, well, different. Consequently, it’s sometimes a good idea to be clear about what the actual test was that you ran, especially if you’re doing something unusual. If you just say “chi-square test”, it’s unclear what test you’re talking about. Although, since the two most common chi-square tests are the goodness of fit test and the independence test (Section <a href="chisquare.html#chisqindependence">9.2</a>), most readers with stats training can probably guess. Nevertheless, it’s something to be aware of.</p>
</div>
</div>
<div id="chisqindependence" class="section level2 hasAnchor" number="9.2">
<h2><span class="header-section-number">9.2</span> The <span class="math inline">\(\chi^2\)</span> test of independence (or association)<a href="chisquare.html#chisqindependence" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The other day Danielle was watching an animated documentary examining the quaint customs of the natives of the planet <em>Chapek 9</em>. Apparently, in order to gain access to their capital city, a visitor must prove that they’re a robot, not a human. In order to determine whether or not the visitor is human, they ask whether the visitor prefers puppies, flowers or large, properly formatted data files. But what if humans and robots have the same preferences? That probably wouldn’t be a very good test then, would it? In order to determine whether or not a visitor is human, the natives of <em>Chapek 9</em> need to know whether or not the visitor’s preferences are independent of their species. In other words, they need to know whether or not the visitor’s preferences are associated with their species.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:cogstatloadchapek9"></span>
<img src="resources/image/cogstatloadchapek9.png" alt="Loading the [`chapek9.csv`](resources/data/chapek9.csv) data set into CogStat."  />
<p class="caption">
Figure 9.4: Loading the <a href="resources/data/chapek9.csv"><code>chapek9.csv</code></a> data set into CogStat.
</p>
</div>
<p>In total, there are 180 entries in the data frame, one for each person (counting both robots and humans as “people”) who was asked to make a choice. Specifically, there are 93 humans and 87 robots.</p>
<p>What we want to do is look at the <code>choices</code> broken down <em>by</em> <code>species</code>. That is, we need to cross-tabulate the data. We cannot use the <code>Pivot table</code> option in CogStat for strings, but we can use the <code>Compare groups</code> option instead. We’ll use the <code>species</code> variable as the grouping variable and the <code>choices</code> variable as the variable to compare.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:cogstatchapek9"></span>
<img src="resources/image/cogstatcomparegroupschapek9.png" alt="Using the `Compare groups` dialogue to get some information about `choices` by `species`."  />
<p class="caption">
Figure 9.5: Using the <code>Compare groups</code> dialogue to get some information about <code>choices</code> by <code>species</code>.
</p>
</div>
<p>The overwhelmingly preferred choice is the <code>data file</code>. You can see a visual representation of this in Figure <a href="chisquare.html#fig:cogstatchapek9mosaic">9.6</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:cogstatchapek9mosaic"></span>
<img src="resources/image/cogstatchapek9mosaic.png" alt="The mosaic plot of `choices` by `species`."  />
<p class="caption">
Figure 9.6: The mosaic plot of <code>choices</code> by <code>species</code>.
</p>
</div>
<p>Scrolling down, you can see the descriptives for the groups in the <code>Sample properties</code> section:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:cogstatchapek9descriptives"></span>
<img src="resources/image/cogstatchapek9descriptives.png" alt="The `Sample properties` section of the `Compare groups` results showing the contingency table we'll discuss later in this chapter."  />
<p class="caption">
Figure 9.7: The <code>Sample properties</code> section of the <code>Compare groups</code> results showing the contingency table we’ll discuss later in this chapter.
</p>
</div>
<p>Let’s put these results in a nice table for our discussion on the <span class="math inline">\(\chi^2\)</span> test of independence.</p>
<table>
<caption>
<span id="tab:unnamed-chunk-23">Table 9.1: </span>Cross-tabulation of <code>choices</code> by <code>species</code>
</caption>
<tbody>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:center;">
Robot
</td>
<td style="text-align:center;">
Human
</td>
<td style="text-align:center;">
Total
</td>
</tr>
<tr>
<td style="text-align:left;">
Puppy
</td>
<td style="text-align:center;">
13
</td>
<td style="text-align:center;">
15
</td>
<td style="text-align:center;">
28
</td>
</tr>
<tr>
<td style="text-align:left;">
Flower
</td>
<td style="text-align:center;">
30
</td>
<td style="text-align:center;">
13
</td>
<td style="text-align:center;">
43
</td>
</tr>
<tr>
<td style="text-align:left;">
Data file
</td>
<td style="text-align:center;">
44
</td>
<td style="text-align:center;">
65
</td>
<td style="text-align:center;">
109
</td>
</tr>
<tr>
<td style="text-align:left;">
Total
</td>
<td style="text-align:center;">
87
</td>
<td style="text-align:center;">
93
</td>
<td style="text-align:center;">
180
</td>
</tr>
</tbody>
</table>
<p>It’s quite clear that most humans chose the data file, whereas the robots tended to be a lot more even in their preferences. Leaving aside the question of <em>why</em> humans might be more likely to choose the data file for the moment, first, we must determine if the discrepancy between human choices and robot choices in the data set is statistically significant.</p>
<div id="constructing-our-hypothesis-test" class="section level3 hasAnchor" number="9.2.1">
<h3><span class="header-section-number">9.2.1</span> Constructing our hypothesis test<a href="chisquare.html#constructing-our-hypothesis-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>How do we analyse this data manually? Specifically, since our <em>research</em> hypothesis is that “humans and robots answer the question in different ways”, how can we construct a test of the <em>null</em> hypothesis that “humans and robots answer the question the same way”? As before, we begin by establishing some notation to describe the data:</p>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
Robot
</th>
<th style="text-align:left;">
Human
</th>
<th style="text-align:left;">
Total
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Puppy
</td>
<td style="text-align:left;">
<span class="math inline">\(O_{11}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(O_{12}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(R_{1}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
Flower
</td>
<td style="text-align:left;">
<span class="math inline">\(O_{21}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(O_{22}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(R_{2}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
Data file
</td>
<td style="text-align:left;">
<span class="math inline">\(O_{31}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(O_{32}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(R_{3}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
Total
</td>
<td style="text-align:left;">
<span class="math inline">\(C_{1}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(C_{2}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(N\)</span>
</td>
</tr>
</tbody>
</table>
<p>In this notation, we say that <span class="math inline">\(O_{ij}\)</span> is a count (observed frequency) of the number of respondents that are of species <span class="math inline">\(j\)</span> (<code>robot</code> or <code>human</code>) who answered <span class="math inline">\(i\)</span> (<code>puppy</code>, <code>flower</code> or <code>data</code>) when asked to make a choice. The total number of observations is written <span class="math inline">\(N\)</span>, as usual. Finally, <span class="math inline">\(R_i\)</span> denotes the row totals (e.g. <span class="math inline">\(R_1\)</span> is the total number of people who chose the flower), and <span class="math inline">\(C_j\)</span> denotes the column totals (e.g., <span class="math inline">\(C_1\)</span> is the total number of robots). To use the terminology from another mathematical statistics textbook <span class="citation">(Hogg et al., 2005)</span>, we should technically refer to this situation as a <strong>chi-square test of homogeneity</strong>; and reserve the term <strong>chi-square test of independence</strong> for the situation where both the row and column totals are random outcomes of the experiment.</p>
<p>So now, let’s think about what the null hypothesis says. If robots and humans are responding in the same way to the question, it means that the probability that “a robot says puppy” is the same as the probability that “a human says puppy”, and so on for the other two possibilities. So, if we use <span class="math inline">\(P_{ij}\)</span> to denote “the probability that a member of species <span class="math inline">\(j\)</span> gives response <span class="math inline">\(i\)</span>”, then our null hypothesis is that:</p>
<table>
<caption>
<span id="tab:chapeknullhypo">Table 9.2: </span>The null hypothesis for the <span class="math inline">\(\chi^2\)</span> test of independence of the <code>chapek9</code> data set.
</caption>
<thead>
<tr>
<th style="text-align:left;">
<span class="math inline">\(H_0\)</span>:
</th>
<th style="text-align:left;">
All of the following are true:
</th>
<th style="text-align:left;">
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
<span class="math inline">\(P_{11} = P_{12}\)</span>
</td>
<td style="text-align:left;">
same probability of saying <code>puppy</code>
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
<span class="math inline">\(P_{21} = P_{22}\)</span>
</td>
<td style="text-align:left;">
same probability of saying <code>flower</code>
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
<span class="math inline">\(P_{31} = P_{32}\)</span>
</td>
<td style="text-align:left;">
same probability of saying <code>data file</code>
</td>
</tr>
</tbody>
</table>
<p>Since the null hypothesis claims that the true choice probabilities don’t depend on the species of the person making the choice, we can let <span class="math inline">\(P_i\)</span> refer to this probability: e.g. <span class="math inline">\(P_1\)</span> is the true probability of choosing the puppy.</p>
<p>Next, in much the same way we did with the goodness of fit test, we need to calculate the expected frequencies. For each of the observed counts <span class="math inline">\(O_{ij}\)</span>, we need to figure out what the null hypothesis would tell us to expect. Let’s denote this expected frequency by <span class="math inline">\(E_{ij}\)</span>. This time, it’s a little bit trickier. If there are a total of <span class="math inline">\(C_j\)</span> people that belong to species <span class="math inline">\(j\)</span>, and the true probability of anyone (regardless of species) choosing option <span class="math inline">\(i\)</span> is <span class="math inline">\(P_i\)</span>, then the expected frequency is just:
<span class="math display">\[
E_{ij} = C_j \times P_i
\]</span></p>
<p>This is all very well and good, but we have a problem. Unlike the situation we had with the goodness of fit test, the null hypothesis doesn’t specify a particular value for <span class="math inline">\(P_i\)</span>. It’s something we have to estimate (Chapter <a href="estimation.html#estimation">7</a>) from the data! Fortunately, this is pretty easy to do. If 28 out of 180 people selected the flowers, then a natural estimate for the probability of choosing flowers is <span class="math inline">\(28/180\)</span>, which is approximately <span class="math inline">\(.16\)</span>. If we phrase this in mathematical terms, what we’re saying is that our estimate for the probability of choosing option <span class="math inline">\(i\)</span> is just the row total divided by the total sample size:
<span class="math display">\[
\hat{P}_i = \frac{R_i}{N}
\]</span></p>
<p>Therefore, our expected frequency can be written as the product (i.e. multiplication) of the row total and the column total, divided by the total number of observations:<a href="#fn39" class="footnote-ref" id="fnref39"><sup>39</sup></a>
<span class="math display">\[
E_{ij} = \frac{R_i \times C_j}{N}
\]</span></p>
<p>Now that we’ve figured out how to calculate the expected frequencies, it’s straightforward to define a test statistic following the same strategy we used in the goodness of fit test. It’s pretty much the <em>same</em> statistic. For a contingency table with <span class="math inline">\(r\)</span> rows and <span class="math inline">\(c\)</span> columns, the equation that defines our <span class="math inline">\(X^2\)</span> statistic is
<span class="math display">\[
X^2 = \sum_{i=1}^r \sum_{j=1}^c \frac{({E}_{ij} - O_{ij})^2}{{E}_{ij}}
\]</span>
The only difference is that we have to include two summation signs (i.e. <span class="math inline">\(\sum\)</span>) to indicate that we’re summing over both rows and columns. As before, large values of <span class="math inline">\(X^2\)</span> suggest that the null hypothesis provides a poor description of the data, whereas small values of <span class="math inline">\(X^2\)</span> indicate that it does a good job of accounting for the data. Therefore, just like last time, we want to reject the null hypothesis if <span class="math inline">\(X^2\)</span> is too large.</p>
<p>Not surprisingly, this statistic is <span class="math inline">\(\chi^2\)</span> distributed. All we need to do is figure out how many degrees of freedom are involved, which actually isn’t too hard. You can think of the degrees of freedom as equal to the number of data points you’re analysing minus the number of constraints. A contingency table with <span class="math inline">\(r\)</span> rows and <span class="math inline">\(c\)</span> columns contains a total of <span class="math inline">\(r \times c\)</span> observed frequencies, so that’s the total number of observations.</p>
<p>What about the constraints? Here, it’s slightly trickier. The answer is always the same:
<span class="math display">\[
df = (r-1)(c-1)
\]</span></p>
<p>But the explanation for <em>why</em> the degrees of freedom take this value is different depending on the experimental design. For the sake of argument, let’s suppose that we had honestly intended to survey exactly 87 robots and 93 humans (column totals fixed by the experimenter) but left the row totals free to vary (row totals are random variables). Let’s think about the constraints that apply here. Well, since we deliberately fixed the column totals, we have <span class="math inline">\(c\)</span> constraints right there. There’s more to it than that. Remember how our null hypothesis had some free parameters (i.e. we had to estimate the <span class="math inline">\(P_i\)</span> values)? Those matter too.</p>
<p>Every free parameter in the null hypothesis is rather like an additional constraint. So, how many of those are there? Well, since these probabilities have to sum to 1, there’s only <span class="math inline">\(r-1\)</span> of these. So our total degree of freedom is:
<span class="math display">\[
\begin{array}{rcl}
df &amp;=&amp; \mbox{(number of observations)} - \mbox{(number of constraints)} \\
&amp;=&amp; (rc) - (c + (r-1)) \\
&amp;=&amp; rc - c - r + 1 \\
&amp;=&amp; (r - 1)(c - 1)
\end{array}
\]</span></p>
<p>Alternatively, suppose that the only thing that the experimenter fixed was the total sample size <span class="math inline">\(N\)</span>. That is, we quizzed the first 180 people that we saw, and it just turned out that 87 were robots and 93 were humans. This time around, our reasoning would be slightly different but would still lead us to the same answer. Our null hypothesis still has <span class="math inline">\(r-1\)</span> free parameters corresponding to the choice probabilities. Still, it now <em>also</em> has <span class="math inline">\(c-1\)</span> free parameters corresponding to the species probabilities because we’d also have to estimate the probability that a randomly sampled person turns out to be a robot.<a href="#fn40" class="footnote-ref" id="fnref40"><sup>40</sup></a> Finally, since we did fix the total number of observations <span class="math inline">\(N\)</span>, that’s one more constraint. So now we have, <span class="math inline">\(rc\)</span> observations, and <span class="math inline">\((c-1) + (r-1) + 1\)</span> constraints. What does that give?
<span class="math display">\[
\begin{array}{rcl}
df &amp;=&amp; \mbox{(number of observations)} - \mbox{(number of constraints)} \\
&amp;=&amp; rc - ( (c-1) + (r-1) + 1) \\
&amp;=&amp; rc - c - r + 1 \\
&amp;=&amp; (r - 1)(c - 1)
\end{array}
\]</span>
Amazing.</p>
</div>
<div id="AssocTestInCogStat" class="section level3 hasAnchor" number="9.2.2">
<h3><span class="header-section-number">9.2.2</span> The test results in CogStat<a href="chisquare.html#AssocTestInCogStat" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The test is automatically done in CogStat using the <code>Compare groups</code> feature. The result set will contain information about the sample and its properties, as seen in Figure <a href="chisquare.html#fig:cogstatchapek9descriptives">9.7</a>. Further scrolling down, you’ll see the effect size (which we will cover in a short while in Chapter <a href="chisquare.html#chisqeffectsize">9.4</a>). The last part of the result set is the hypothesis test itself (see Figure <a href="chisquare.html#fig:cogstatchapek9hypo">9.8</a>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:cogstatchapek9hypo"></span>
<img src="resources/image/cogstatchapek9hypo.png" alt="Population properties and Hypothesis tests for the `chapek9.csv` data set." width="100%" />
<p class="caption">
Figure 9.8: Population properties and Hypothesis tests for the <code>chapek9.csv</code> data set.
</p>
</div>
<p>Let us go through the <code>Hypothesis tests</code> section line by line.</p>
      <div style="margin: 0 0 1.275em; border: 1px solid #ddd; padding:.85em 1em;">
            <p style="font-size:medium; font-weight:600; color:#3960a5;">Hypothesis tests</p>
            <p style="color:#008000;">Testing if the distributions are the same.<br/>One grouping variable. Two groups. Nominal variable. &gt;&gt; Running chi-squared test.</p>
            <p style="color:black">Sensitivity power analysis. Minimal effect size to reach 95% power with the present sample size for the present hypothesis test. Minimal effect size in w: 0.29.</p>
            <p>Result of the Pearson's chi-squared test: &#967;<span style=" vertical-align:super;">2</span>(2, <span style=" font-style:italic;">N</span> = 180) = 10.72, <span style=" font-style:italic;">p</span> = .005</p>
      </div>
<ul>
<li><code>Testing if the distributions are the same.</code>: This, in plain English, tells us that we are testing for a null hypothesis where all distributions, or probabilities, are the same. It does not differ in essence from the <span class="math inline">\(H_0\)</span> we described more eloquently in Table <a href="chisquare.html#tab:chapeknullhypo">9.2</a>.</li>
<li><code>One grouping variable.</code>: This says we are looking at only one variable by which we have dissected our data: <code>species</code>.</li>
<li><code>Two groups</code>: This tells us that we have two groups, <code>robot</code> and <code>human</code>.</li>
<li><code>Nominal variable.</code>: This tells us that the variable we are looking at is categorical.</li>
<li><code>Running chi-squared test.</code>: Well, this is obvious.</li>
</ul>
<p>Let us ignore the details about the 95% confidence interval, minimal effect size w, and Cramér’s V (Figure <a href="chisquare.html#fig:cogstatchapek9hypo">9.8</a>) for now. We will come back to them in Chapter <a href="chisquare.html#chisqeffectsize">9.4</a>.</p>
<p><code>Result of the Pearson's chi-squared test:</code></p>
<p><span class="math display">\[
\chi^2(2, N = 180) = 10.72, p = 0.005
\]</span></p>
<p>The test result is 10.72, the degree of freedom is 2 with 180 observations, and the p-value is 0.005. This means that the null hypothesis is rejected at the 0.005 level of significance.</p>
<p>This output gives us enough information to write up the result:</p>
<blockquote>
<p>Pearson’s <span class="math inline">\(\chi^2\)</span> revealed a significant association between species and choice (<span class="math inline">\(\chi^2(2) = 10.72, p &lt; .01\)</span>): robots appeared to be more likely to say that they prefer flowers, but the humans were more likely to say they prefer data.</p>
</blockquote>
<p>Notice that, once again, we provided a little bit of interpretation to help the human reader understand what’s going on with the data. This is a good habit to get into. It’s also a good idea to report the effect size, which we will do in the next section.</p>
</div>
</div>
<div id="yates" class="section level2 hasAnchor" number="9.3">
<h2><span class="header-section-number">9.3</span> Yates correction for 1 degree of freedom<a href="chisquare.html#yates" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Time for a little bit of a digression. You need to make a tiny change to your calculations whenever you only have 1 degree of freedom. It’s called the <strong>continuity correction</strong>, or sometimes the <strong>Yates correction</strong>.</p>
<p>The <span class="math inline">\(\chi^2\)</span> test is based on an approximation, specifically on the assumption that binomial distribution starts to look like a normal distribution for large <span class="math inline">\(N\)</span>. One problem with this is that it often doesn’t quite work, especially when you’ve only got 1 degree of freedom (e.g. when you’re doing a test of independence on a <span class="math inline">\(2 \times 2\)</span> contingency table). The main reason for this is that the true sampling distribution for the <span class="math inline">\(X^2\)</span> statistic is actually discrete (because you’re dealing with categorical data!), but the <span class="math inline">\(\chi^2\)</span> distribution is continuous. This can introduce systematic problems. Specifically, when <span class="math inline">\(N\)</span> is small and when <span class="math inline">\(df=1\)</span>, the goodness of fit statistic tends to be “too big”, meaning that you actually have a bigger <span class="math inline">\(\alpha\)</span> value than you think (or, equivalently, the <span class="math inline">\(p\)</span> values are a bit too small). <span class="citation">Yates (1934)</span> suggested a simple fix, in which you redefine the goodness of fit statistic as:
<span class="math display">\[
X^2 = \sum_{i} \frac{(|E_i - O_i| - 0.5)^2}{E_i}
\]</span>
Basically, he subtracts off 0.5 everywhere. The correction is basically a hack. It’s not derived from any principled theory: rather, it’s based on an examination of the behaviour of the test and observing that the corrected version seems to work better.</p>
<p>CogStat (or any other software, for that matter) introduces this correction, so it’s useful to know what it is about. You won’t know when it happens because the CogStat output doesn’t explicitly say that it has used a “continuity correction” or “Yates’ correction”.<a href="#fn41" class="footnote-ref" id="fnref41"><sup>41</sup></a></p>
<p>Let us overwrite all the <code>puppy</code> answers in our <code>chapek9</code> data frame to look at 1 degree of freedom (Figure <a href="chisquare.html#fig:chapek9two">9.9</a>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:chapek9two"></span>
<img src="resources/image/cogstatchapek9twomatrix.png" alt="CogStat results for [`chapek9two.csv`](resources/data/chapek9two.csv) with 1 degree of freedom" width="100%" /><img src="resources/image/cogstatchapek9tworesult.png" alt="CogStat results for [`chapek9two.csv`](resources/data/chapek9two.csv) with 1 degree of freedom" width="100%" />
<p class="caption">
Figure 9.9: CogStat results for <a href="resources/data/chapek9two.csv"><code>chapek9two.csv</code></a> with 1 degree of freedom
</p>
</div>
<p>The result as calculated by default with the Yates correction is:
<span class="math display">\[
\chi^2(1, N = 180) = 6.24, p = 0.013
\]</span></p>
<p>However, if CogStat didn’t do the correction, the results would have been <span class="math inline">\(\chi^2(2, N = 180) = 7.02, p = 0.008\)</span>, which is a bit different. The difference is not huge, but it is there. The Yates correction is a good thing to know about, but it’s not something you need to worry about too much. It’s just a little bit of a hack that makes the test work better in this specific case.</p>
</div>
<div id="chisqeffectsize" class="section level2 hasAnchor" number="9.4">
<h2><span class="header-section-number">9.4</span> Effect size (Cramér’s <span class="math inline">\(V\)</span>)<a href="chisquare.html#chisqeffectsize" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As we discussed earlier in Chapter <a href="hypothesistesting.html#effectsize">8.7</a>, it’s becoming commonplace to ask researchers to report some measure of effect size. So, suppose that you’ve run your chi-square test, which turns out to be significant. So you now know that there is some association between your variables (independence test) or some deviation from the specified probabilities (goodness of fit test). Now you want to report a measure of effect size. That is, given that there is an association/deviation, how strong is it?</p>
<p>There are several different measures you can choose to report and several different tools you can use to calculate them. By default, the two measures that people tend to report most frequently are the <span class="math inline">\(\phi\)</span> statistic and the somewhat superior version, known as Cramér’s <span class="math inline">\(V\)</span>. While CogStat gives you only Cramér’s <span class="math inline">\(V\)</span>, we need to start with <span class="math inline">\(\phi\)</span> because they are related.</p>
<p>Mathematically, they’re both very simple. To calculate the <span class="math inline">\(\phi\)</span> statistic, you just divide your <span class="math inline">\(X^2\)</span> value by the sample size and take the square root:
<span class="math display">\[
\phi = \sqrt{\frac{X^2}{N}}
\]</span></p>
<p>The idea here is that the <span class="math inline">\(\phi\)</span> statistic is supposed to range between 0 (no association at all) and 1 (perfect association). However, it doesn’t always do this when your contingency table is bigger than <span class="math inline">\(2 \times 2\)</span> (like in our original chapek9 data set), which is a total pain. So, to correct this, people usually prefer to report the <span class="math inline">\(V\)</span> statistic proposed by <span class="citation">Cramér (1946)</span>. It’s a pretty simple adjustment to <span class="math inline">\(\phi\)</span>. If you’ve got a contingency table with <span class="math inline">\(r\)</span> rows and <span class="math inline">\(c\)</span> columns, then define <span class="math inline">\(k = \min(r,c)\)</span> to be the smaller of the two values. If so, then <strong>Cramér’s <span class="math inline">\(V\)</span></strong> statistic is
<span class="math display">\[
\phi_c = \sqrt{\frac{X^2}{N(k-1)}}
\]</span>
And you’re done. This seems to be a reasonably popular measure, presumably because it’s easy to calculate, and it gives answers that aren’t completely silly: you know that <span class="math inline">\(V\)</span> does range from <em>0 (no association at all)</em> to <em>1 (perfect association)</em>.</p>
<p>Calculating <span class="math inline">\(V\)</span> is automatic in CogStat, as you’ve seen in the result sets earlier in both the original chapek9 data set (Figure <a href="chisquare.html#fig:cogstatchapek9hypo">9.8</a>) and the modified one (Figure <a href="chisquare.html#fig:chapek9two">9.9</a>). Now let’s look at the original chapek9 effect size.</p>
        <div style="margin: 0 0 1.275em; border: 1px solid #ddd; padding:.85em 1em;">
            <p style="font-size: medium; font-weight: 600; color: #3960a5;">Standardized effect sizes</p> 
            <table style="border: 0px; background-color: white;">
                <tr>
                    <td style="border: 0px; background-color: white;"></td>
                    <td style="border: 0px; background-color: white;">Value</td>
                </tr>
                <tr>
                    <td style="border: 0px; background-color: white; padding-right: 10px">Cram&eacute;r's V measure of association</td>
                    <td style="border: 0px; background-color: white;">&#981;<sub>c</sub> = 0.244</td>
                </tr>
            </table>
        </div>
<p>A Cramer’s V of 0.244 tells us that there is a moderate association between the two variables. The usual guidance is that anything below 0.2 is a weak association, 0.2 to 0.6 is a moderate association, and anything above 0.6 is a strong association. However, you must always look at the context of your data when determining the effect size.</p>
</div>
<div id="chisqassumptions" class="section level2 hasAnchor" number="9.5">
<h2><span class="header-section-number">9.5</span> Assumptions of the test(s)<a href="chisquare.html#chisqassumptions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>All statistical tests make assumptions, and it’s usually a good idea to check that those assumptions are met. For the chi-square tests discussed so far in this chapter, the assumptions are:</p>
<ul>
<li><em>Expected frequencies are sufficiently large</em>. Remember how in the previous section, we saw that the <span class="math inline">\(\chi^2\)</span> sampling distribution emerges because the binomial distribution is similar to a normal distribution? Well, as we discussed in Chapter <a href="probability.html#probability">6</a>, this is only true when the number of observations is sufficiently large. What that means in practice is that all of the expected frequencies need to be reasonably big. How big is reasonably big? Opinions differ, but the default assumption seems to be that you generally would like to see all your expected frequencies larger than about 5, though for larger tables, you would probably be okay if at least 80% of the expected frequencies are above 5 and none of them are below 1. However, these seem to have been proposed as rough guidelines, not hard and fast rules; and they seem somewhat conservative [Larntz1978].</li>
<li><em>Data are independent of one another</em>. One somewhat hidden assumption of the chi-square test is that you have to believe that the observations are genuinely independent. Suppose we are interested in the proportion of babies born at a particular hospital that are boys. We walk around the maternity wards and observe 20 girls and only 10 boys. Seems like a pretty convincing difference, right? But later on, it turns out that we’d actually walked into the same ward 10 times, and in fact, we’d only seen 2 girls and 1 boy. Not as convincing, is it? Our original 30 <em>observations</em> were massively non-independent. And were only, in fact, equivalent to 3 independent observations. Obviously, this is an extreme(ly silly) example, but it illustrates the fundamental issue. Non-independence “stuffs things up”. Sometimes it causes you to falsely reject the null, as the silly hospital example illustrates, but it can go the other way too. Let’s consider what would happen if we’d done the cards experiment slightly differently: instead of asking 200 people to try to imagine sampling one card at random, suppose we asked 50 people to select 4 cards. One possibility would be that <em>everyone</em> selects one heart, one club, one diamond and one spade (in keeping with the “representativeness heuristic”; Tversky &amp; Kahneman 1974). This is highly non-random behaviour from people, but in this case, we would get an observed frequency of 50 for all four suits. For this example, the fact that the observations are non-independent (because the four cards that you pick will be related to each other) actually leads to the opposite effect, falsely retaining the null.</li>
</ul>
<p>If you find yourself in a situation where independence is violated, it may be possible to use the McNemar test or the Cochran test. Similarly, if your expected cell counts are too small, check out the Fisher exact test.</p>
</div>
<div id="fisherexacttest" class="section level2 hasAnchor" number="9.6">
<h2><span class="header-section-number">9.6</span> The Fisher exact test<a href="chisquare.html#fisherexacttest" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>What should you do if your cell counts are too small, but you’d still like to test the null hypothesis that the two variables are independent? One answer would be “collect more data”, but that’s far too glib: there are a lot of situations in which it would be either infeasible or unethical to do. If so, statisticians are morally obligated to provide scientists with better tests. In this instance, Fisher (1922) kindly provided the right answer to the question. To illustrate the basic idea, let’s suppose we’re analysing data from a field experiment, looking at the emotional status of people accused of witchcraft. Some of them are currently being burned at the stake.<a href="#fn42" class="footnote-ref" id="fnref42"><sup>42</sup></a> Unfortunately for the scientist (but rather fortunately for the general populace), it’s quite hard to find people in the process of being set on fire, so the cell counts are microscopic. The <a href="resources/data/salem.csv"><code>salem.csv</code></a> file illustrates the point.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:cogstatsalemload"></span>
<img src="resources/image/cogstatsalemload.png" alt="The `salem` data set" width="100%" />
<p class="caption">
Figure 9.10: The <code>salem</code> data set
</p>
</div>
<p>Looking at this data, you’d be hard pressed not to suspect that people not on fire are more likely to be happy than people on fire. However, the chi-square test (even with the Yates correction for the 2x2 data) makes this very hard to test because of the small sample size.</p>
<p><img src="resources/image/cogstatsalemresult.png" width="100%" style="display: block; margin: auto;" /></p>
<p>We’d <em>really</em> like to be able to get a better answer than this provided we really don’t want to be on fire. This is where <strong>Fisher’s exact test</strong> comes in very handy. The Fisher exact test works somewhat differently to the chi-square test (or in fact any of the other hypothesis tests that I talk about in this book) insofar as it doesn’t have a test statistic; it calculates the <span class="math inline">\(p\)</span>-value “directly”.</p>
<p>Let’s have some notation:</p>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
Happy
</th>
<th style="text-align:left;">
Sad
</th>
<th style="text-align:left;">
Total
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Set on fire
</td>
<td style="text-align:left;">
<span class="math inline">\(O_{11}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(O_{12}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(R_{1}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
Not set on fire
</td>
<td style="text-align:left;">
<span class="math inline">\(O_{21}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(O_{22}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(R_{2}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
Total
</td>
<td style="text-align:left;">
<span class="math inline">\(C_{1}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(C_{2}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(N\)</span>
</td>
</tr>
</tbody>
</table>
<p>In order to construct the test Fisher treats both the row and column totals (<span class="math inline">\(R_1\)</span>, <span class="math inline">\(R_2\)</span>, <span class="math inline">\(C_1\)</span> and <span class="math inline">\(C_2\)</span>) are known, fixed quantities; and then calculates the probability that we would have obtained the observed frequencies that we did (<span class="math inline">\(O_{11}\)</span>, <span class="math inline">\(O_{12}\)</span>, <span class="math inline">\(O_{21}\)</span> and <span class="math inline">\(O_{22}\)</span>) given those totals. In the notation that we developed in Chapter <a href="probability.html#probability">6</a> this is written:
<span class="math display">\[
P(O_{11}, O_{12}, O_{21}, O_{22} \ | \ R_1, R_2, C_1, C_2)
\]</span>
and as you might imagine, it’s a slightly tricky exercise to figure out what this probability is, but it turns out that this probability is described by a distribution known as the <em>hypergeometric distribution</em>. Now that we know this, what we have to do to calculate our <span class="math inline">\(p\)</span>-value is calculate the probability of observing this particular table <em>or a table that is “more extreme”</em>.<a href="#fn43" class="footnote-ref" id="fnref43"><sup>43</sup></a> Back in the 1920s, computing this sum was daunting even in the simplest of situations, but these days it’s pretty easy as long as the tables aren’t too big and the sample size isn’t too large. The conceptually tricky issue is to figure out what it means to say that one contingency table is more “extreme” than another. The easiest solution is to say that the table with the lowest probability is the most extreme. This then gives us the <span class="math inline">\(p\)</span>-value of <span class="math inline">\(0.03571\)</span>.</p>
<p>The implementation of the test in CogStat is not yet available. The main thing we’re interested in here is the <span class="math inline">\(p\)</span>-value, which in this case is small enough (<span class="math inline">\(p=.036\)</span>) to justify rejecting the null hypothesis that people on fire are just as happy as people not on fire.</p>
</div>
<div id="mcnemar" class="section level2 hasAnchor" number="9.7">
<h2><span class="header-section-number">9.7</span> The McNemar test<a href="chisquare.html#mcnemar" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Suppose you’ve been hired to work for the <em>Australian Generic Political Party</em> (AGPP), and part of your job is to find out how effective the AGPP political advertisements are. So, what you do, is you put together a sample of <span class="math inline">\(N=100\)</span> people and ask them to watch the AGPP ads. Before they see anything, you ask them if they intend to vote for the AGPP; after showing the ads, you ask them again to see if anyone has changed their minds. One way to describe your data is via the following contingency table:</p>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:center;">
Before
</th>
<th style="text-align:center;">
After
</th>
<th style="text-align:center;">
Total
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Yes
</td>
<td style="text-align:center;">
30
</td>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
40
</td>
</tr>
<tr>
<td style="text-align:left;">
No
</td>
<td style="text-align:center;">
70
</td>
<td style="text-align:center;">
90
</td>
<td style="text-align:center;">
160
</td>
</tr>
<tr>
<td style="text-align:left;">
Total
</td>
<td style="text-align:center;">
100
</td>
<td style="text-align:center;">
100
</td>
<td style="text-align:center;">
200
</td>
</tr>
</tbody>
</table>
<p>At first pass, you might think that this situation lends itself to the Pearson <span class="math inline">\(\chi^2\)</span> test of independence (as per Chapter <a href="chisquare.html#chisqindependence">9.2</a>). However, we’ve got a problem: we have 100 participants but 200 observations. This is because each person has given us an answer in <em>both</em> the before and after columns. What this means is that the 200 observations aren’t independent of each other: if voter A says “yes” the first time and voter B says “no”, then you’d expect that voter A is more likely to say “yes” the second time than voter B! The consequence of this is that the usual <span class="math inline">\(\chi^2\)</span> test won’t give trustworthy answers due to the violation of the independence assumption. Now, if this were a really uncommon situation, I wouldn’t be bothering to waste your time talking about it. But it’s not uncommon at all: this is a <em>standard</em> repeated measures design, and none of the tests we’ve considered so far can handle it.</p>
<p>The solution to the problem was published by <span class="citation">McNemar (1947)</span>. The trick is to start by tabulating your data in a slightly different way:</p>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:center;">
Before: Yes
</th>
<th style="text-align:center;">
Before: No
</th>
<th style="text-align:center;">
Total
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
After: Yes
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
10
</td>
</tr>
<tr>
<td style="text-align:left;">
After: No
</td>
<td style="text-align:center;">
25
</td>
<td style="text-align:center;">
65
</td>
<td style="text-align:center;">
90
</td>
</tr>
<tr>
<td style="text-align:left;">
Total
</td>
<td style="text-align:center;">
30
</td>
<td style="text-align:center;">
70
</td>
<td style="text-align:center;">
100
</td>
</tr>
</tbody>
</table>
<p>This is exactly the same data, but it’s been rewritten so that each of our 100 participants appears in only one cell. Because we’ve written our data this way, the independence assumption is now satisfied, and this is a contingency table that we <em>can</em> use to construct an <span class="math inline">\(X^2\)</span> goodness of fit statistic. However, as we’ll see, we need to do it in a slightly nonstandard way. To see what’s going on, it helps to label the entries in our table a little differently:</p>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:center;">
Before: Yes
</th>
<th style="text-align:center;">
Before: No
</th>
<th style="text-align:center;">
Total
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
After: Yes
</td>
<td style="text-align:center;">
<span class="math inline">\(a\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(b\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(a+b\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
After: No
</td>
<td style="text-align:center;">
<span class="math inline">\(c\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(d\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(c+d\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
Total
</td>
<td style="text-align:center;">
<span class="math inline">\(a+c\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(b+d\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n\)</span>
</td>
</tr>
</tbody>
</table>
<p>Next, let’s think about what our null hypothesis is: it’s that the “before” test and the “after” test have the same proportion of people saying, “Yes, I will vote for AGPP”. Because of the way we have rewritten the data, it means that we’re now testing the hypothesis that the <em>row totals</em> and <em>column totals</em> come from the same distribution. Thus, the null hypothesis in McNemar’s test is that we have “marginal homogeneity”. That is, the row totals and column totals have the same distribution: <span class="math inline">\(P_a + P_b = P_a + P_c\)</span>, and similarly that <span class="math inline">\(P_c + P_d = P_b + P_d\)</span>. Notice that this means that the null hypothesis actually simplifies to <span class="math inline">\(P_b = P_c\)</span>.</p>
<p>In other words, as far as the McNemar test is concerned, it’s only the off-diagonal entries in this table (i.e. <span class="math inline">\(b\)</span> and <span class="math inline">\(c\)</span>) that matter! After noticing this, the <strong>McNemar test of marginal homogeneity</strong> is no different to a usual <span class="math inline">\(\chi^2\)</span> test. After (automatically) applying the Yates correction, our test statistic becomes:
<span class="math display">\[
X^2 = \frac{(|b-c| - 0.5)^2}{b+c}
\]</span>
or, to revert to the notation that we used earlier in this chapter:
<span class="math display">\[
X^2 = \frac{(|O_{12}-O_{21}| - 0.5)^2}{O_{12} + O_{21}}
\]</span>
and this statistic has an (approximately) <span class="math inline">\(\chi^2\)</span> distribution with <span class="math inline">\(df=1\)</span>. However, remember that – just like the other <span class="math inline">\(\chi^2\)</span> tests – it’s only an approximation, so you need to have reasonably large expected cell counts for it to work.</p>
<p>Now that you know what the McNemar test is all about, lets actually run one. The <a href="resources/data/agpp.csv"><code>agpp.csv</code></a> file contains the raw data. It contains three variables, an <code>id</code> variable that labels each participant in the data set, a <code>responseBefore</code> variable that records the person’s answer when they were asked the question the first time, and a <code>responseAfter</code> variable that shows the answer that they gave when asked the same question a second time.</p>
<p><img src="resources/image/cogstatloadagpp.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Let us think what we want to do here. We have the same participants giving us two answers. We want to test whether the two answers (the <em>before</em> and the <em>after</em>) are independent of each other. Or, in other words, we want to compare a <strong>reapeated measure</strong>. In CogStat, we need to select <code>Compare repeated measures variables</code> and add the <code>responseBefore</code> and <code>responseAfter</code> variables to the <code>Selected variables</code> box to run an analysis (Figure <a href="chisquare.html#fig:cogstatrepeatagpp">9.11</a>). The results are shown in Figure <a href="chisquare.html#fig:cogstatagppresults">9.12</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:cogstatrepeatagpp"></span>
<img src="resources/image/cogstatrepeatagpp.png" alt="Repeated measures analysis of the AGPP data in CogStat." width="100%" />
<p class="caption">
Figure 9.11: Repeated measures analysis of the AGPP data in CogStat.
</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:cogstatagppresults"></span>
<img src="resources/image/cogstatagppresults1.png" alt="Results of the repeated measures analysis of the AGPP data in CogStat." width="100%" /><img src="resources/image/cogstatagppresults2.png" alt="Results of the repeated measures analysis of the AGPP data in CogStat." width="100%" />
<p class="caption">
Figure 9.12: Results of the repeated measures analysis of the AGPP data in CogStat.
</p>
</div>
      <div style="margin: 0 0 1.275em; border: 1px solid #ddd; padding:.85em 1em;">
            <p style="font-size:medium; font-weight:600; color:#3960a5;">Hypothesis tests</p>
            <p style="color:#008000;">Testing if the distributions are the same.<br />
            Two variables. Nominal dichotomous variables. &gt;&gt; Running McNemar test.</p>
            <p style="color:black;">Result of the McNemar test: &#967;<span style=" vertical-align:super;">2</span>(1, <span style=" font-style:italic;">N</span> = 100) = 12.03, <span style="font-style:italic;">p</span> &lt; .001</p>
      </div>
<p>And we’re done. We’ve just run a McNemar’s test automatically, since our data set was identified by CogStat as categorical data.</p>
<p>The results would tell us something like this:</p>
<blockquote>
<p>The test was significant (<span class="math inline">\(\chi^2(1) = 12.03, p&lt;.001\)</span>), suggesting that people were not just as likely to vote AGPP after the ads as they were before hand. In fact, the ads had a negative effect: people were less likely to vote AGPP after seeing the ads.</p>
</blockquote>
</div>
<div id="whats-the-difference-between-mcnemar-and-independence" class="section level2 hasAnchor" number="9.8">
<h2><span class="header-section-number">9.8</span> What’s the difference between McNemar and independence?<a href="chisquare.html#whats-the-difference-between-mcnemar-and-independence" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let’s go back to the beginning of the chapter and look at the <code>cards</code> data set again. If you recall, the experimental design described involved people making <em>two</em> choices. Because we have information about the first choice and the second choice that everyone made, we can construct the following contingency table that cross-tabulates the first choice against the second choice.</p>
<table>
<caption>
<span id="tab:unnamed-chunk-29">Table 9.3: </span>Contingency table for the cards data set as seen in CogStat when runnig <code>Compare repeated measures variables</code> or <code>Explore relation of variable pair</code>.
</caption>
<tbody>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
clubs
</td>
<td style="text-align:left;">
diamonds
</td>
<td style="text-align:left;">
hearts
</td>
<td style="text-align:left;">
spades
</td>
<td style="text-align:left;">
Total
</td>
</tr>
<tr>
<td style="text-align:left;">
clubs
</td>
<td style="text-align:left;">
10
</td>
<td style="text-align:left;">
9
</td>
<td style="text-align:left;">
10
</td>
<td style="text-align:left;">
6
</td>
<td style="text-align:left;">
35
</td>
</tr>
<tr>
<td style="text-align:left;">
diamonds
</td>
<td style="text-align:left;">
20
</td>
<td style="text-align:left;">
4
</td>
<td style="text-align:left;">
13
</td>
<td style="text-align:left;">
14
</td>
<td style="text-align:left;">
51
</td>
</tr>
<tr>
<td style="text-align:left;">
hearts
</td>
<td style="text-align:left;">
20
</td>
<td style="text-align:left;">
18
</td>
<td style="text-align:left;">
3
</td>
<td style="text-align:left;">
23
</td>
<td style="text-align:left;">
64
</td>
</tr>
<tr>
<td style="text-align:left;">
spades
</td>
<td style="text-align:left;">
18
</td>
<td style="text-align:left;">
13
</td>
<td style="text-align:left;">
15
</td>
<td style="text-align:left;">
4
</td>
<td style="text-align:left;">
50
</td>
</tr>
<tr>
<td style="text-align:left;">
Total
</td>
<td style="text-align:left;">
68
</td>
<td style="text-align:left;">
44
</td>
<td style="text-align:left;">
41
</td>
<td style="text-align:left;">
47
</td>
<td style="text-align:left;">
200
</td>
</tr>
</tbody>
</table>
<p>First, we wanted to know whether the choice you make the second time is dependent on the choice you made the first time (for this, we’ll run the <code>Explore relation of variable pair</code> analysis). This is where a test of independence is useful, and what we’re trying to do is see if there’s some relationship between the rows and columns of this table.</p>
<p>Second, we wanted to know if <em>on average</em>, the frequencies of suit choices were different the second time than the first time. In that situation, we’re trying to see if the row totals in <code>cardChoices</code> (i.e. the frequencies for <code>choice_1</code>) are different from the column totals (i.e. the frequencies for <code>choice_2</code>). That’s when we’d use the McNemar test. However, when running the <code>Compare repeated measures variables</code> analysis, we get an error, as the function for non-dichotomous nominal data is not implemented yet.</p>
<p>Here’s the result if we run the <code>Explore relation of variable pair</code> analysis in CogStat:</p>
      <div style="margin: 0 0 1.275em; border: 1px solid #ddd; padding:.85em 1em;">
            <p style="font-size:medium; font-weight:600; color:#3960a5;">Hypothesis tests</p>
            <p style="color:#008000;">Testing if variables are independent.<br />
            Nominal variables. &gt;&gt; Running Cram&eacute;r's V.</p>
            <p style="color:black;">Sensitivity power analysis. Minimal effect size to reach 95% power with the present sample size for the present hypothesis test. Minimal effect size in w: 0.34.</p>
            <p style="color:black;">Result of the Pearson's chi-squared test: &#967;<span style=" vertical-align:super;">2</span>(9, <span style=" font-style:italic;">N</span> = 200) = 29.24, <span style="font-style:italic;">p</span> &lt; .001</p>
      </div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:cogstatmcn"></span>
<img src="resources/image/cogstatmcn1.png" alt="Hypothesis test results when running either `Compare repeated measures variables` or `Explore relation of variable pair` in CogStat." width="100%" /><img src="resources/image/cogstatmcn2.png" alt="Hypothesis test results when running either `Compare repeated measures variables` or `Explore relation of variable pair` in CogStat." width="100%" />
<p class="caption">
Figure 9.13: Hypothesis test results when running either <code>Compare repeated measures variables</code> or <code>Explore relation of variable pair</code> in CogStat.
</p>
</div>
<p>For the second case, running the McNemar test, the answer would be McNemar’s chi-squared = <span class="math inline">\(16.03\)</span>, df = <span class="math inline">\(6\)</span>, p-value = <span class="math inline">\(0.014\)</span>. This is a significant result, suggesting that the frequencies of suit choices were different the second time than the first time.</p>
<p>Notice that the results are different! These aren’t the same test.</p>
</div>
<div id="summary-5" class="section level2 hasAnchor" number="9.9">
<h2><span class="header-section-number">9.9</span> Summary<a href="chisquare.html#summary-5" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The key ideas discussed in this chapter are:</p>
<ul>
<li>The chi-square goodness of fit test (Section <a href="chisquare.html#goftest">9.1</a>) is used when you have a table of observed frequencies of different categories; the null hypothesis gives you a set of “known” probabilities to compare them to.</li>
<li>The chi-square test of independence (Section <a href="chisquare.html#chisqindependence">9.2</a>) is used when you have a contingency table (cross-tabulation) of two categorical variables. The null hypothesis is that there is no relationship/association between the variables.</li>
<li>Effect size for a contingency table can be measured in several ways (Section <a href="chisquare.html#chisqeffectsize">9.4</a>). In particular, we noted the Cramér’s <span class="math inline">\(V\)</span> statistic.</li>
<li>Both versions of the Pearson test rely on two assumptions: that the expected frequencies are sufficiently large and that the observations are independent (Section <a href="chisquare.html#chisqassumptions">9.5</a>). The Fisher exact test (Section <a href="chisquare.html#fisherexacttest">9.6</a>) can be used when the expected frequencies are small. The McNemar test (Section <a href="chisquare.html#mcnemar">9.7</a>) can be used for some kinds of violations of independence.</li>
</ul>
<p>If you’re interested in learning more about categorical data analysis, an excellent first choice would be <span class="citation">Agresti (1996)</span>, which, as the title suggests, provides an <em>Introduction to Categorical Data Analysis</em>. If the introductory book isn’t enough for you (or you can’t solve the problem you’re working on), you could consider <span class="citation">Agresti (2002)</span>, <em>Categorical Data Analysis</em>. The latter is a more advanced text, so it’s probably not wise to jump straight from this book to that one.</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="35">
<li id="fn35"><p>This, again, is an over-simplification. It works nicely for quite a few situations, but every now and then, we’ll come across degrees of freedom values that aren’t whole numbers. Don’t let this worry you too much – when you come across this, just remind yourself that “degrees of freedom” is actually a bit of a messy concept. For an introductory class, it’s usually best to stick to the simple story.<a href="chisquare.html#fnref35" class="footnote-back">↩︎</a></p></li>
<li id="fn36"><p>In practice, the sample size isn’t always fixed… e.g. we might run the experiment over a fixed period of time, and the number of people participating depends on how many people show up. That doesn’t matter for the current purposes.<a href="chisquare.html#fnref36" class="footnote-back">↩︎</a></p></li>
<li id="fn37"><p>To some people, this advice might sound odd or at least in conflict with the “usual” advice on how to write a technical report. Students are typically told that the “results” section of a report is for describing the data and reporting statistical analysis, and the “discussion” section provides interpretation. That’s true as far as it goes, but people often interpret it way too literally. Provide a quick and simple interpretation of the data in the results section so that the reader understands what the data are telling us. Then, in the discussion, try to tell a bigger story; about how my results fit the rest of the scientific literature. In short, don’t let the “interpretation goes in the discussion” advice turn your results section into incomprehensible garbage. Being understood by your reader is <em>much</em> more important.<a href="chisquare.html#fnref37" class="footnote-back">↩︎</a></p></li>
<li id="fn38"><p>Complicating matters, the <span class="math inline">\(G\)</span>-test is a special case of a whole class of tests that are known as <em>likelihood ratio tests</em>.<a href="chisquare.html#fnref38" class="footnote-back">↩︎</a></p></li>
<li id="fn39"><p>Technically, <span class="math inline">\(E_{ij}\)</span> here is an estimate, so we should probably write it <span class="math inline">\(\hat{E}_{ij}\)</span>.<a href="chisquare.html#fnref39" class="footnote-back">↩︎</a></p></li>
<li id="fn40"><p>A problem many of us worry about in real life.<a href="chisquare.html#fnref40" class="footnote-back">↩︎</a></p></li>
<li id="fn41"><p>Technically, CogStat uses <code>chi2_contingency</code> function from <code>scipy</code> without specifying the <code>correction</code> parameter which defaults to <code>true</code>.<a href="chisquare.html#fnref41" class="footnote-back">↩︎</a></p></li>
<li id="fn42"><p>This example is based on a joke article published in the <em>Journal of Irreproducible Results</em>.<a href="chisquare.html#fnref42" class="footnote-back">↩︎</a></p></li>
<li id="fn43"><p>Not surprisingly, the Fisher exact test is motivated by Fisher’s interpretation of a <span class="math inline">\(p\)</span>-value, not Neyman’s!<a href="chisquare.html#fnref43" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="hypothesistesting.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ttest.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"number_sections": true,
"fig_caption": true
},
"toc_depth": 2,
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
